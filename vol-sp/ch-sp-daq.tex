\chapter{Data Acquisition}
\label{ch:sp-daq}

%%% todo

% Assign candidate names to sections and solicit them to write notes and/or presentations.

% Start and maintain a list holding links to all relevant notes and presentations.

\fixme{\textbf{Authors:}

  See \url{https://wiki.dunescience.org/wiki/Technical_Design_Report}
  for general guidance. 

  While this chapter is still in outline, \textbf{check that it hits all
  the required points} some of which are:

  We are to describe a \textbf{baseline} or \textbf{process to
  decide a baseline}.

  \textbf{BE SUCCINCT} $TDR \approx IDR + 10\%$, goal is 50 pages for
  this chapter. 

  You are encouraged to produce \textbf{tech notes} with any
  supporting verbosity which may be referenced.

  State requirements and demonstrate how they are met, use
  standardized requirements table.

  Emphasize safety and professionalism (projectisms: cost, schedule,
  risks, interfaces).}

\metainfo{Some sections of this chapter must be written generically
  and without any reference to module-specific terms. They are marked
  with an orange ``fixme'' box. 
  Yellow info boxes like this one provide guidance for the content. 
  This guidance is not comprehensive so authors may provide additional
  information but retaining \textbf{conciseness} and \textbf{not
    repeating} info in other section is required.}

\section{Introduction}
\label{sec:fd-daq:introduction}
% \fixme{module-generic}

% \metainfo{A brief introduction to this chapter describing what will be
%   described.  This is \textbf{not} an overview of the DAQ itself.
%   Keep it brief. Do \textbf{not} write a conceptual overview here,
%   that is below, reference it. 
%   Do \textbf{not} use module-specific language but \textbf{do}
%   describe how commonalities are described in text shared by both
%   SP/DP volumes and specialized sections appear only in their
%   respective volume. 
%   \textbf{Do} describe the lexicographical convention used to demark
%   shared sections (this needs coordination with other chapters in the
%   same boat).}

The design of the \dword{dune} \dword{fd} \dfirst{daq} system is described in this chapter.  The DAQ services all \dword{fd} \dwords{detmodule}.  Most  aspects of the design are identical across the different \dwords{detmodule} and they are described in sections below which are reproduced verbatim in this \dword{daq} chapter in each \dword{detmodule} TDR volume.  A minority portion of the DAQ design that must be tailored to meet module-specific requirements are documented in sections below which are unique to each \dword{detmodule} TDR volume.  These sections are identified simply by their module-specific language.

The sections below begin with the requirements for and interfaces between DAQ and other DUNE systems.  A section comparing the \dword{protodune} experiment with DUNE is given to highlight important information learned from that prototype and what still must be understood.  The subsequent section describes the design itself.  The chapter finishes with giving details on project management issues such as production, installation, cost, schedule, safety, and other items.

\section{Requirements}
\label{sec:fd-daq:requirements}
\fixme{module-generic}

\metainfo{One sentence introducing the contents of this section.}

\fixme{The following are notes that need integration.}
\begin{itemize}
\item Requirements derived from Giovanna's CCM note:
\begin{itemize}
\item It shall be possible to take data simultaneously and independently from different subsets of the \dword{fd}.  Each subset is called a \dword{daqpart}.
\item The DAQ shall minimize downtime for data acquisition and whenever possible continue nominal operations in parallel with any subset being taken offline or employed for any exceptional use.
\item Transitioning between \dwords{daqrun} shall require little to no downtime and shall require no downtime for \dwords{daqpart} unrelated to the transition.  
\end{itemize}
\item Design guidelines from CCM note:
  \begin{itemize}
  \item A \dword{daqrun} is identified with a \dword{daqrunnum}.
  \item The components of the DAQ shall be asynchronous and loosely coupled and in particular no global control of their state shall be centrally controlled.  Synchronization shall be performed dynamically and in a distributed fashion. 
  \item The DAQ shall be robust against intentional and unexpected removal and addition of individual components. 
    Single points of failure should not exist and may only be allowed based on a cost/risk analysis.
  \item Detector coverage and DAQ data selection criteria shall be recorded.  Coincident with intentional changes and upon discovery of unintentional changes the DAQ shall transition to a new \dword{daqrun}.
  \item Unexpected failures in the operation of DAQ components should be automatically detected, reported, and handled so as to minimize system and human reaction time and to minimize reliance on human intervention.
  \end{itemize}
\end{itemize}
\fixme{The above are notes that need integration.}

\subsection{Specifications}
\label{sec:sd-daq:specifications}
\fixme{single-phase module}


\metainfo{Include rows of top-level requirements table (``Schmitz''
  table) here. 
  Augment that with any additional requirements of our determining. 
  Eg: accept data from detector electronics, perform reduction to
  satisfy output rate limit, allow for cross-module triggering,
  collect beam activity with XX\%, SNB requirements, noise level,
  total thermal and space envelop, etc....}

\metainfo{Include message passing requirements and domains.}

\subsection{Design Philosophy}

\metainfo{Describe how the design addresses the requirements.}

\subsection{Parameters}
\label{sec:sp-daq:parameters}
\fixme{single-phase module}

\metainfo{Include a table which lists all important parameters driving
  the design.  Sampling rate and resolution, channel count}


\section{Interfaces}
\label{sec:sp-daq:interfaces}
\metainfo{Include interface summary and table here.}
\subsection{TPC Cold Electronics}
\metainfo{Data reception physical and logical, configuration information delivery.}
\subsection{PDS Readout System}
\metainfo{Data reception physical and logical, configuration information delivery.}
\subsection{Computing}
\metainfo{Buffer disk. 
  Agreement on sysadmin support and computer procurement, ssh gateways, non data networks. 
  Address reference how the data model described above is acceptable.}
\subsection{CISC}
\label{sec:sp-daq:interfaces-cisc}
\subsection{Calibration}
\subsection{Timing}
\metainfo{Note, this is an ``outgoing'' interface from DAQ's Timing System to various others. 
  Instead of making this section explicit we may instead disperse Timing System interface information among the other Interface sections where appropriate.}

\section{ProtoDUNE and DUNE Comparison}

\metainfo{Here we write what similarities and differences there are between ProtoDUNE and DUNE DAQ designs.}

\subsection{Detector Readout Hardware}

\metainfo{Compare and contrast design elements related to the detector readout hardware.}

\subsubsection{RCE}

\subsubsection{FELIX}

\subsection{Backend Event Building}

\subsection{Other}

\section{DAQ Design}
\label{sec:fd-daq:design}
% \fixme{module-generic}

% \metainfo{One sentence to introduce the section. 
%   Listing the subsections and describing which are generic and which
%   are X-phase specific.}

This section describes the DAQ design. 
It begins with a conceptual overview followed by sections giving the design of the DAQ subsystems. 
First come the \dword{ipc} and \dword{ccm} subsystems.
Next is the \dword{fe} data receiver and data handling and processing subsystems.
Then, the subsystems for data selection and the DAQ back-end are described Finally, the timing subsystem is presented and this section finishes with plans for design validation and development.


The following descriptions of the design are kept brief due to page limitations. 
More details are provided as technical notes as listed in Table~\ref{tab:fd-daq:tech-notes}.

\begin{dunetable}{|p{0.7\textwidth}|p{0.2\textwidth}|}{tab:fd-daq:tech-notes}{Summary of relevant and detailed DAQ technical notes.}
  Title & References \\
  DUNE Far Detector Data Volumes & \citedocdb{9240}\\
  The DAQ for the single phase DUNE Prototype at CERN & \citedocdb{8708}\\
  A System for Communication Between DAQ Elements & \citedocdb{10482}\\
  Data Selection for DUNE Beam and Atmospheric Events & \citedocdb{11215}\\
  Data orchestrator and event building for DUNE FD DAQ & t.b.d. \\
  DUNE Run Control, Configuration \& Monitoring (CCM) & t.b.d. \\
  DUNE DAQ Readout & t.b.d. \\
\end{dunetable}



\subsection{Overview}
\label{sec:fd-daq:design-overview}
%\fixme{module-generic}

\begin{dunefigure}{fig:daq-conceptual-overview}{DAQ Conceptual
    Subsystem Overview.  See text for description.}
  \includegraphics[width=0.8\textwidth]{daq-toplevel-conceptual.pdf}
\end{dunefigure}

% \metainfo{This is the \textbf{only} place to describe the conceptual
%   overview. 
%   Do \textbf{not} repeat this info in sections below. 
%   \textbf{Do} use \textbf{module-neutral} terms.
%   \textbf{Do} describe major interface between each subsystem (the edges between the circles in Fig~\ref{fig:daq-conceptual-overview}).
%   \textbf{Do} mention that concrete systems span portions of the
%   conceptual subsystems and how the following subsections are defined
%   along these concrete deliverable lines.}

An illustration of the conceptual parts which make up the DUNE FD DAQ is given in Fig.~\ref{fig:daq-conceptual-overview}. 
It applies to all \dword{fd} modules. 
The box in the illustration indicates the overall scope of the DAQ.
Each of the various concrete hardware and software subsystems describe later in this section provide a portion of one or more of the conceptual subsystems represented by the circles in the figure.
Approximately following the data flow through the DAQ, the concept starts with receiving input via optical fibers from the detector electronics (see Section~\ref{sec:fd-daq:design-felix}). 
The flow then bifurcates. 
The entirety of the input flow is buffered for a period of time sufficient to satisfy triggering and readout requirements (see Section~\ref{sec:sp-daq:design-fe-processing}). 
The second flow need contain only data that is to be used to form a \dword{trigdecision} (see Section~\ref{sec:sp-daq:design-selection-algs}).
The information in that decision is used by the egress subsystem to query back to the appropriate buffers and thus retrieve selected data (see Section~\ref{sec:fd-daq:design-backend}).
The results are aggregated and saved to files on nonvolatile storage media at which point custody is transferred to offline responsibility.
This is all orchestrated by the \dword{ccm} subsystem (Section~\ref{sec:fd-daq:design-run-control}) shown in the center of the figure.   The various information flows, represented by the arrows of the figure, ride on the \dword{ipc} subsystems (Section~\ref{sec:fd-daq:design-messages}). 

\metainfo{Include components summary and table here.  Need guidance on what is wanted.}

\fixme{Where will we describe partitions?}
As described more in Section~\ref{sec:fd-daq:partitions}, this conceptual picture is implemented in terms of a number of \dwords{daqpart} or instances. 
The primary set of partitions will exist underground in the \dword{cuc} in order to service the \dword{fd} modules. 
As described more in Section~\ref{sec:sp-daq:production} the DAQ will connect to and begin servicing portions of a \dword{fd} module after they are installed and commissioned. 
There will also be a DAQ presence in the \dword{itf} to support the work there during detector construction.
% \metainfo{Include physical location description}




\metainfo{For the remaining design sections: do not include directly validation info but rather place this information in section~\ref{sec:sp-daq:design-validation} and make references.}
  



\subsection{Inter-process Communication}
\label{sec:fd-daq:design-messages}
\fixme{module-generic}

The DAQ must transfer data of various schema, latency and throughput. 
For the most part these transfers must be reliable in that once data is sent it is received if the recipient is accessible on the network and operational. 
As detailed in Section~\ref{sec:sp-daq:design-selection-algs}, one particularly critical element is the unit which makes the pinnacle trigger decision. 
It shall be developed to support redundancy. 
This will largely be satisfied by having IPC communication units follow the \dword{pubsub}.


Choices of IPC systems impact performance, functionality, development and support costs among others. 
Some subsystem solutions bring their own IPC system while developers of the required novel systems must select a suitable IPC system. 
The choice is one which must balance trade-offs. 
The development philosophy is to minimize the number of distinct IPC systems while embracing existing ones which accompany high quality solutions for implementing subsystems.

In general, an IPC domain covers IPC units which have support for the associated IPC system. 
The DUNE FD DAQ shall select and develop a \textit{lingua franca} IPC system to be used for inter-domain IPC and as a candidate for direct use in any required novel development.  Any domain that does not naively support the \textit{lingua franca} IPC shall have a proxy or gateway unit developed that translates between the two.

An example of a subsystem that shall support the IPC \textit{lingua franca} is the hierarchical trigger processing system provided by the data selection (Section~\ref{sec:sp-daq:design-selection-algs}. 
An example of a subsystem providing its own IPC domain is artDAQ which shall provide the heart of the egress system (Section~\ref{sec:fd-daq:design-backend}).
The DAQ shall also interface with external domains. 
For example, a two way exchange of information between DAQ and \dword{cisc} shall be developed as described in Section~\ref{sec:sp-daq:interfaces-cisc}.

\fixme{Shall we name ZeroMQ specifically as the basis for the \textit{lingua franca} IPC?}

% \metainfo{Describe the domains requiring message passing.  A domain means parts that shall share the same message passing infrastructure.  Eg, the hierarchical trigger system is one.  The transfer of data between artDAQ nodes is another.  Run control, monitoring and logging is a third.  Some MP domains will exist in other consortia and must interface with DAQ MP domains.  Each internal or external interface must be at least listed.   Describe how effort will be conserved by minimizing the number of distinct domains to the extent it makes sense.  Some examples: two-way comms with CISC (CISC tells DAQ of HV it shut down, DAQ tells CISC about hardware health, DAQ process health, statistics on things like per-unit trigger rates), handling laser triggers (eg, want laser to only fire in between beam spills).}

% \metainfo{We may not be ready to give concrete designs for every domain.  Where this is the case, we must describe a plan for determining the IPC system for each domain.}

%\metainfo{IPC must support redundant paths for trigger information, especially at the MLT level and above, to assure robustness.}


\subsection{Control, Configuration and Monitoring}
\label{sec:fd-daq:design-run-control}
\fixme{module-generic}

\metainfo{Describe run control and DAQ operation monitoring. 
  How it makes use of the Message Passing System. 
  What is an ``epoch''.
  How Epoch Change Requests lead to zero down time reconfiguration. 
  Public key based ``iron'' authentication between run control processes and the controlled processes. 
  Describe how RC will configure partitioning, initiate reconfiguration, handle ``run'' changes, node discovery, configuration, logging, startup, shutdown and failures are handled. Describe how RC will support detector electronics configuration.}

The \dword{ccm} subsystem encompasses all the software that is needed to control, configure and monitor the rest of the DAQ and to some extent elements of its own subsystem. 
It acts as a glue for the different DAQ components allowing them to be treated and managed as a coherent system, while not dealing directly with the primary transport of physics data, nor with their selection, nor with the orchestration of the data movement. 
A pictorial view of the central role of the \dword{ccm} within the complete DAQ system was shown in Figure~\ref{fig:daq-conceptual-overview}.

The \dword{ccm} is composed of three main sub-systems are briefly defined here and then detailed in the following sections.
\begin{description}

\item[Control] sub-system actively manages DAQ software process lifetimes, asserts access control policies, executes commands, initiates change, detects and handles exceptions and provides human interface.


\item[Configuration] sub-system retains and provides access to current and historical information about the intended configuration of the high-level structure of the \dwords{daqpart} and the low-level configuration applied to each of their connected components.

\item[Monitoring] sub-system accepts, stores and makes available current and historical status information collected from \dwords{daqpart} and their components.

\end{description}

\begin{dunefigure}{fig:daq-ccm-subsys}{Main interaction between the three CCM sub-systems.}
  \includegraphics[width=0.8\textwidth]{daq-ccm-subsys.pdf}
\end{dunefigure}

The three \dword{ccm} sub-systems interact and operate together to guarantee efficient data taking.  As shown in Figure~\ref{fig:daq-ccm-subsys}, the Control sub-system relies on the Configuration to know which components participate the DAQ instance, which policies to apply for resource management and error handling and uses the Monitoring in order to retrieve the status of DAQ components and detect any anomalies.

It shall be noted that, while the CCM system is instrumental to the definition of the data taking conditions, the conditions database, as well as the definition of which conditions are important for offline analysis are not part of the CCM. The CCM will provide any required information in response to network requests.

\subsubsection{Control}
\label{sec:daq:design:ccm:control}

The DAQ Control sub-system is composed of a number of functional blocks in global or partition scope as illustrated in Figure~\ref{fig:daq-ccm-control}. 
Those blocks shown in partition scope have instances created for each partition. 

\fixme{I (bv) redrew this from Giovanna's to get vector PDF and match DUNE color palette.  I made two content changes: 1: move UI out of partition as it can't both initiate a partition and be inside it and likely will allow for creation/viewing of more than just one partition.  2: I had to guess on how garbage collection might go and so addded a line from RM to PM. }

\begin{dunefigure}{fig:daq-ccm-control}{Roles and services which compose the DAQ Control sub-system.}
  \includegraphics[width=0.8\textwidth]{daq-ccm-control.pdf}
\end{dunefigure}

The functional blocks represent one or more semi-autonomous and redundant agents each with defined roles, capabilities and access.  First the blocks at partition scope are described.

\begin{description}
\item[Partition naming service] This block provides \dword{daqdispre} at the scope of one \dword{daqpart}. 
  The block provides a mechanism for a component in the partition to learn of the existence of others, their identities as well as determine if they are currently operational or have become unresponsive.

\item[Run control] Starting a \dword{rc} block is the first step toward initiating a \dword{daqpart}. 
  The \dword{rc} shall accept, interpret and validate input commands.  The commands shall describe the desired initial state of the aggregate of all components which are to comprise the \dword{daqpart}.  \dword{rc} may query other blocks to perform validation and then shall execute the commands by allocating processes through Process management.  Once successfully allocated, their lifetime is managed by \dword{rc}.  Throughout their lifetime \dword{rc} may reconfigure existing processes, destroy them or allocate additional processes.  \dword{rc} may query the Partition naming service to resolve resource identifiers referenced in commands to network endpoints.  

\item[Supervisor] The initiation of a \dword{rc} block shall coincide with the initiating of a Supervisor block.  This block shall augment human commands with automated ones such as those needed for \dword{rc} to initiate actions to recover from some exception.

\end{description}

Global scope controls DAQ components for all \dwords{daqpart} across all \dword{fd} modules\footnote{DAQ instances at locations other than the \dword{fd} cavern are expected to be wholly distinct.}.  It consists of the following blocks.


\begin{description}
\item[Global naming service] This role aggregates the \dword{daqdispre} information across the partitions and in particular regarding the \dword{rc} instances.

\item[Process management] This role allocates and may reclaim sets of processes on behalf of a requesting component (specifically \dword{rc} and Resource management). 
  An allocation request shall include a complete description of the processes and their initial configuration information. 
  A successful allocation shall occur only after this role initiates all processes and confirms their presence. 
  Process management shall only allocate if the requester has sufficient access privileges as determined by Access management and if sufficient resources exist as determined by Resource management.
  
\item[Resource management] This role shall determine if any process allocation may proceed and provides process garbage collection. 
  Resource management shall monitor the presence of all successful allocations as well as that of their requester.  
  An allocation shall be accepted only if the resulting aggregate of processes violate no constraints maintained by Resulting management.
  Resource management shall notify Process management of any remaining processes from an allocation when it detects that the requester has ceased to assert presence.
  This role shall also support allocation pre-validation queries. 
  The response to shall indicate whether the allocation would succeed at the current time but such a query shall not be interpreted as an allocation. 
  No guarantee may be provided that the allocation may succeed or fail if subsequently requested.

  
\item[Access management] This role is responsible for providing authentication and authorization for all DAQ functions which require access control.  

\end{description}

\fixme{Should Process management return a partial allocation is a portion of processes fail?}

Finally, a small number of applications shall provide human interfaces to the Control sub-system. 
In particular, an application shall be developed which allows a trained operator to construct and issue commands required to initiate, configure, potentially reconfigure and finally terminate \dwords{daqpart}. 
The UI shall confirm the user possesses sufficient authentication and authorization for a command to be executed by the \dword{rc} prior to allowing the user to attempt to construct it. 
The UI may pre-validate that there are currently sufficient resources to execute the command to be issued.

\fixme{Re the above paragraph: The line from UI to RM feels ``wrong'' to me. 
  It sets up a race condition and requires the same type of message to go along two different paths.  It also causes a second line to AM.  I think better, the ``pre-validate'' of a allocation should be made via UI to PM whereby UI tells PM ``just checking''.  This leaves just race condition but makes the message paths simpler.  To remove the race condition then I think we need some kind of ``ticket'' mechanism whereby UI (or others) pre-allocate with PM.  PM either allocates then or in some way reserves the allocation, then then returns a cookie.  The cookie is passed in the command to RC which then uses it to ``claim'' the allocation.  Somewhat convoluted but no race.}

\subsubsection{Configuration}
\label{sec:daq:design:ccm:configuration}

The DAQ Configuration sub-system shall a persistent data store for all historic, current and potential future configuration information applicable to the DAQ.
Further, it shall maintain a record of the use of any configuration for every \dword{daqrun} and it shall provide for allocation of unique \dwords{daqrunnum}. 
All data stores shall be insert-only and shall not support updating or deletion of existing records.
The stores shall support the following types of information.

\begin{description}

\item[Partition structure] shall contain descriptions of the multiplicity and connectivity of DAQ components for any partition which has or may be formed. 
  Structure shall be expressed in an abstract manner and ultimately in terms identifiers associated with logical addresses of detector electronics. \footnote{Mapping from abstract to concrete addressing may be done through the discovery and presence provided by naming services described in Section~\ref{sec:daq:design:ccm:control}.}

\item[Component parameters] shall contain descriptions of configuration parameter sets associated with any DAQ component that has or may be initiated.  It shall accommodate data schema specific to each type of component. 

\item[Run number] shall provide a sole source atomic allocation of unique, monotonically increasing \dwords{daqrunnum}.

\item[Partition instances] shall provide a record, associated with a run number, of the partition structure and set of component parameters used to initiate a \dword{daqpart} or applied to a subsequent reconfiguration.  Records may consist of references into the subsequent stores.

\item[Constraints] shall provide definitions of all constraints that have been or may be considered by Resource management. 
  It shall record which constraint was employed by Resource management over time.
\end{description}


All stores provided by the Configuration subsystem shall provide a redundant access mechanism that assures any other requirement such as atomic run number allocations. 
The access mechanism may be provided as a layer between client access and store implementation.
For stores of data structures of complexity prohibitive to manual construction configuration editors and generators shall be developed.

backups, offsite replication


\subsubsection{Monitoring}

The DAQ Monitoring sub-system is intended assist humans and expert systems in the detection, diagnosis and correction of anomalous activity, observation of intended operation and provide a historical record.
It shall accept the required information produced by any DAQ component (here called ``status'').
Status shall be stored a period not less than that required for the corresponding detector data to undergo initial offline data quality validation.
Status shall be made available in a form suitable for human understanding promptly. 
The required latency defining promptness needs further study and is expected to vary depending on the type of status and the purpose of its consumption.  
Status shall be retrieved based on the time it was produced and the logical and physical addresses associated with its producer.
This may be satisfied by developing status views accessing the status stores or it may be provided by views which subscribe to one or more of the status feeds provided by individual components.

The precise implementation of the production, acceptance, store, post-processing, querying, visualization of monitored status requires additional development. 
However, the selected \textit{linuga franca} IPC system described in Section~\ref{sec:fd-daq:design-messages} shall be used to deliver status information to the Monitoring sub-system. 
Where this may conflict with a native IPC used by some subsystem a proxy may be supplied. 

In general, the \dword{pubsub} network communication pattern shall be followed. 
The Monitoring system may be further decomposed into a number high-level IPC protocols which are specified in terms of their message types and schema and the behavioral expectations at either endpoint of a connection.
These are categorized as:


\begin{description}
\item[Common] all protocols shall have commonalities in terms of message identifiers including: \dword{pubsub} topic, sub-protocol type, message type, sender, host computer time and where applicable associated detector data time.  Specific protocols extend this by providing additional ``payload'' to their messages as described in the following items.
 
\item[Logging] payload consists of an integer determining subjective importance (eg, enumerating categories: debug, info, warning, error, fatal) and a succinct, human-readable information string providing explanation of what led to the occurrence including static type and variable information. 
\item[Metrics] payload consist of message in structure schema and carrying specific information about predefined aspects of the sender.  This is much like logging but the messages support automated consumption by expert systems.  
\item[Quality] payload consists of summary information derived from the detector data (eg waveforms) or its metadata (eg timestamps, error codes) while it is in flight through the DAQ.
\end{description}

Some status feeds accepted by the Monitoring sub-system may be processed and only the resulting data sent to permanent store. 
In particular the quality stream data rate may be prohibitively excessive so as to disallow long term storage in forms that meet the query requirements given above. 
For example, this stream may be summarized into histograms or other statistical representations which shall be saved while the full input quality stream shall be discarded.

\subsection{Detector Reaout}
\label{sec:fd-daq:readout}
\fixme{module-generic}

The DUNE DAQ Readout system is the first element in the data flow chain of the DAQ system.
Conceptually, this system corresponds to the receiver, buffer and a portion of the trigger subsystems illustrated in Figure~\ref{fig:daq-conceptual-overview}.
It is physically connected to the detector electronics via optical fiber and buffers and serves data to other DAQ sub-systems, namely the Data Selection and the Event Builder as detailed in Figure~\ref{fig:daq:readout}.\fixme{It would be nice to redraw this using DUNE colors.}

\begin{dunefigure}{fig:daq:readout}{DUNE DAQ Readout system and its connections.}
  \includegraphics[width=0.8\textwidth]{daq-readout.png}
\end{dunefigure}

The Readout system is composed of many similar \dword{daqrou}, each connected to a sub-set of electronics from a detector module and interfacing to the DAQ switched network.  Each unit encompasses four functional blocks:

\begin{enumerate}
\item Data reception
\item Network based I/O
\item Data processing
\item Temporary data storage
\end{enumerate}

Each of these facets are described below.  In addition and like all other DAQ sub-systems, the readout participates in the common software framework for control, configuration and monitoring as described in Section~\ref{sec:fd-daq:design-run-control}.

\subsubsection{Data reception}

The physical interface between the detector electronics and the DAQ for the purpose of data transmission are 10 Gbps point-to-point serial optical links, running a simple (e.g. 8/10 bit encoded) protocol. 
The number of links per DUNE module vary from about 1000 to 2000, depending on the adopted detectors technologies.

In order minimize the space and power consumption footprint of the DAQ, 10-20 links are aggregated into \dword{felix} boards hosted in \dword{cots} computers. 
\dword{felix} is an FPGA-based PCIe board developed initially for ATLAS and now proposed or in use in a number of experiments including ProtoDUNE. 
Existing firmware shall be adopted and adapted to ensure decoding and format checking of the incoming data and to then marshal the data to the other blocks of the readout sub-system.

\subsubsection{Network based I/O}

The Readout system is connected to the data selection and event building systems through a \dword{cots} switched network.
While the communication protocols are not yet fully defined and will be chosen in due time to minimize cost and match the required performance, the flow of data in and out of the Readout system are already outlined (see Figure~\ref{fig:daq:readout}). 
It is assumed that the network I/O will be handled by the \dwords{daqrou} via software and that no dedicated hardware or firmware development will be required for this functional block.

\subsubsection{Data processing}

The data processing functional block is in charge of the identification of active areas in the detector (in the TPC and photon detection systems) as a function of time.

As a preliminary step data may be pre-processed, i.e. organized in the way that best suits the subsequent data analysis. This may imply reorganizing data into different streams, applying noise filtering algorithms, compressing and/or zero-suppressing data.

The identified detector activity (aka ``hit finding'') is summarized by the Readout system into so-called trigger primitives that are forwarded to the Data Selection system, to make correlations and take a decision on whether and which data shall be saved.

This functional block may be implemented onto FPGAs, GPUs, CPUs or in a mixed fashion. A decision on the implementation is premature at this stage and this is one of the main R\&D topics to explore in the Readout area.

\subsubsection{Temporary storage}

In DUNE, the Readout system is in charge of storing the data until the Data Selection system has formed a decision and such that the Egress system may have sufficient time to request the corresponding data.
There are a number of time scales and data throughput which dictate the technology and its scale which is required to satisfy these requests.

The first is driven by the predominant physics which produces visible activity promptly after interaction and compactly in space and time. 
The latency to form a trigger condition in this case is dominated by processing speed and pipeline depths and is expected to be on order of one second.  The amount of data which is expected to be requested as a result of such decisions is on order one or two TPC drift times (5-10\si{\milli\second} depending on detector technology).

On the other hand the very rare but important case of a potential \dword{snb} has substantially different and more stringent requirements. 
Potentially many seconds of activity may occur which is too infrequent and low energy to form a trigger decision but which can have important physics information. 
In order to capture that, when a \dword{snb} decision is formed the DAQ shall record at least the prior 10 seconds of data. 
\dword{snb} occurrences are so important that all data shall be recorded over their expected duration. 
To satisfy that, the DAQ shall record a minimum of 30 seconds of data from a \dword{snb} trigger decision. 
The data rates and volumes involved in satisfying these requirements are such that different technology and scale must be employed compared to that required to select data from compact interactions.

The worse-case temporary storage requirement for the readout system (using single phase detector technology as a metric) is in the order of 100 TB per DUNE detector module, with a throughout of approximately 10 Tb/s.
This figure is challenging, but technically achievable already with today’s technologies, with a suited granularity of the \dwords{daqrou}. 

It is expected that in this area requirements will still be refined during the detailed design phase of the DAQ system, taking into account the ability of partially compressing data as well as more realistic estimates on trigger decision latency, etc.


% \metainfo{Describe how FELIX hardware defines an interface which common to all modules.  Describe how the hardware may handle UDP or other prototocols including bidirectional communication.  Describe how FELIX can be scaled to accept data across a spectrum in order from large to small data rate: the full SP data from the WIBs, full compressed data from the DP, trigger primitive stream from FPGA based units placed between WIBs and FELIX.}


% \ifdp
% \subsubsection{DP data ingest via UDP}
% \label{sec:dp-daq:design-udp-ingest}
% \fixme{dual-phase module, move to DP-DAQ chapter eventually}
% \metainfo{This is a DP section and will be only in the DP volume. 
%   It should describe the ``Bump On Wire'' from the IDR unless we can
%   come up with any new/better ideas.}
% \metainfo{Include full hardware scope starting at fibers from CE and
%   ending at the output of trigger processors and the interface between
%   buffer and the Data Selector.
%   Describe the per-APA multiplicity of computers, CPU cores, host
%   system RAM, host system storage, FELIX boards, DPM components (RAM,
%   SSD). 
%   Include thermal estimates itemized by components.}  
% \fi

% \subsection{Front-end Data Handling and Processing}
% \label{sec:sp-daq:design-fe-processing}

% \metainfo{This section describes four functional blocks: (1) 10s RAM buffer (minimum), (2) non-volatile SNB buffer for 30s of data once per month (minimum), (3) hardware for the production of trigger primitive including any data formatting and DPS filtering and (4) compression of selected data.  Note, actual algorithms for trigger primitives are described in Section~\ref{sec:sp-daq:design-selection-algs}.}

% \metainfo{One or two sentences that positions the two processing
%   patterns (FEDHP either before or after FELIX) in this section as options. 
%   Say that the ``FPGA before FELIX'' option is used for ``baseline costing''.}

% \metainfo{Include a table with one row for each known compression factor: protoDUNE RCE and FELIX, MicroBooNE before and after noise filter (see docdb), 35t, protoDUNE data after ADC stuck code mitigation or avoidance, simulations.  One column of this table shall give a brief comment of how it applies to DUNE including any caveats or reasons for over/under estimation.}

% % \subsubsection{FELIX+FPGA}
% \subsubsection{Upstream FPGA and Firmware}
% \label{sec:sp-daq:design-felix-fpga}
% \fixme{single-phase module}

% \metainfo{Include full hardware scope starting at fibers from CE and
%   ending at the output of trigger processors and the interface between
%   buffer and the Data Selector.
%   Describe the per-APA multiplicity of computers, CPU cores, host
%   system RAM, host system storage, FELIX boards, DPM components (RAM,
%   SSD). 
%   Include thermal estimates itemized by components.}

% % \subsubsection{FELIX+CPU}
% \subsubsection{Downstream CPU and Software}
% \label{sec:sp-daq:design-felix-cpu}
% \fixme{single-phase module}

% \metainfo{Include full hardware scope starting at fibers from CE and
%   ending at the output of trigger processors and the interface between
%   buffer and the Data Selector. 
%   Describe the per-APA multiplicity of computers, CPU cores, host
%   system RAM, SSD and FELIX boards. 
%   Include thermal estimates itemized by components.}


% \subsubsection{Photon Detection System Interface}

% \metainfo{Some motivations for using light to trigger. 
%   (1) want to understand PDS so want to trigger on just the PDS. 
%   (2) background to SNB for which PDS trigger primitives may eliminate. 
%   (3) possibly must rely on light only for SNB triggering, eg if noise is out of control. 
%   Some to all of these should be included.}

% \metainfo{Possibly want to \SI{1}{\micro\second} packet for every time a 1-PE threshold is crossed. 
%   PDS is still understanding what they may send. 
%   DAQ needs to be in control of the trigger forming.}

% \ifdp
% \subsubsection{DP TPC FE issues}

% \fixme{dual-phase module}

% \metainfo{This is similar to SP except for the need to decompress before any trigger primitive processing.  Decompression can potentially happen on FELIX FPGA or on CPU.  There shall be a table or description of the amount of processing required.}

% \subsubsection{DP SP Issues}
% \fixme{dual-phase module}
% \fi

\subsection{(empty)}

\fixme{This section was merged with above and should be removed.  Leaving it in temporally to not confuse numbered writing assignments.}


\subsection{Data Selection}
\label{sec:sp-daq:design-selection-algs}
\fixme{single-phase module}

\fixme{There are many studies which could go into this section. Some of this may very likely be moved into one or more tech notes and referenced.}


Data Selection must make the decision about what data will be
transferred to the Backend Subsystem. 
It does by providing the core payload software which runs in message
passing nodes. 
In particular it provides the trigger primitive, candidate and
command hierarchy.

\metainfo{One sentence that briefly describes the ``bow tie''
  hierarchy: primitive, candidate, command, query. 
  Do not repeat too much what is in the design overview. 
}


\subsubsection{Trigger Primitives}
\label{sec:sp-daq:design-trigger-primitives}
\fixme{single-phase module}

\fixme{Trigger primitive algorithms run inside of the hardware of \ref{sec:sp-daq:design-fe-processing} but conceptually are more intimate with the Data Selection.  That section should reference this section.}

\metainfo{Describe what they are, how they are formed, storage size on disk, message schema. 
  This section describes algorithms with references to where those algorithms may run (FPGA firmware or CPU software)} \metainfo{Reference the section that provides validation.}


\metainfo{Include plot and discussion of DUNE trigger primitive rate in protoDUNE. 
  The fact that this includes many more cosmics will not matter much as the rate is expected to be dominated by Ar39. 
  Phil has this already but the LAr purity is not yet high enough to see Ar39 across the whole drift distance.}

\subsection{Back-end System}
\label{sec:fd-daq:design-backend}
\fixme{module-generic}

\metainfo{This subsystem starts with receiving trigger commands from MTL, based on their content it queries Data Selectors on all front end computers, forms events, writes files to offline buffer disk. 
  It may perform ``offline'' type processing along the way.}


\subsubsection{Event builder}
\label{sec:fd-daq:design-event-builder}
\fixme{module-generic}

\metainfo{Explain artDAQ, handling of trigger commands by asynchronous, parallel queries to front end Data Selector (but take care not to duplicate between here and in the overview).}

\subsubsection{L2 Data Reduction}

\subsubsection{Data Quality Monitoring}

\subsubsection{Data Model}
\label{sec:fd-daq:design-data-model}
\fixme{module-generic}

\metainfo{Describe the data model. 
  This isn't a strict schema just things like how various parts of the
  detector readout map to files, etc.}

\subsubsection{Output Buffer}

\metainfo{Describe the output buffer system, how it's shared with offline, data hand-off prototocols.  Responsibility scope (eg, who handles transfer to FNAL).}

\subsection{Timing Distribution}
\label{sec:sp-daq:design-timing}
\fixme{single-phase module}
\fixme{Is it indeed still single-phase specific?}

\metainfo{Hardware, consumers, links.}

\subsection{Design Validation and Development Plan}
\label{sec:sp-daq:design-validation}
\fixme{single-phase module}

\metainfo{One sentence to describe our validation strategy: exploit
  ProtoDUNE, use simulation and develope vertical slice tests. 
  Put each validation study (performed or future) in a subsubsection
  and describe either \textbf{how it justifies a decision} or
  \textbf{how its outcome will be used to make a decision in the
    future}.}

\subsubsection{FELIX Throughput Demonstration at ProtoDUNE-SP}
\label{sec:sp-daq:validation-pdune-felix}
\fixme{single-phase module}

\metainfo{Describe how the FELIX DAQ at ProtoDUNE-SP demonstrates a
  FELIX+CPU approach. 
  Describe the elements that are same or similar (full-rate to host
  RAM buffer) and different (higher-rate but external trigger).}


\subsubsection{RCE Throughput Demonstration at ProtoDUNE-SP}
\label{sec:sp-daq:validation-pdune-rce}
\fixme{single-phase module}

\metainfo{Describe how RCE DAQ at ProtoDUNE-SP demonstrates an FPGA
  approach with DUNE.}

\subsubsection{Trigger Primitives in Software}
\label{sec:sp-daq:validation-software-trigger-primitives}
\fixme{single-phase module}
 
\metainfo{Succinctly describe algorithm, include physics and computing
  performance numbers.}

\subsubsection{Trigger Primitives in Firmware}
\label{sec:sp-daq:validation-firmware-trigger-primitives}
\fixme{single-phase module}

\metainfo{Succinctly describe algorithm, include physics and computing
  performance numbers.}

\subsubsection{Vertical Slice Demonstrations}
\label{sec:sp-daq:validation-demonstrators}
\fixme{single-phase module}

\metainfo{Describe VST demonstrators and why we must build them.}

\subsubsection{Prototype Message Passing System}
\label{sec:fd-daq:validation-demonstrators}
\fixme{module-generic}

\metainfo{This is actually module-generic. 
  Very briefly describe the prototype message passing. 
  This will mostly refer to a tech note.}

\subsubsection{Another validation....}
\fixme{write me, as needed}

\section{Production, Assembly, Installation and Integration}
\label{sec:sp-daq:production}

\metainfo{Describe how hardware, firmware and software will produced. }


\metainfo{Describe how we get stuff in place underground (and in the
  ITF), how we will put it all together and make sure it works. 
  What can we do to minimize the effort needed underground both in
  terms of physical work but also in working out the bugs both in
  individual processes and in emergent behavior of the system as a
  whole?}

\subsection{Computing Hardware}

\subsection{Custom Hardware Fabrication}

\subsection{Software and Firmware Development}
\metainfo{Processes and practices.}

\subsection{ITF}

\section{Cost, Schedule, Safety and Risk Summary}
\label{sec:sp-daq:cost}
\metainfo{
Include cost summary and table here.
Include schedule summary and table here.
Include risk summary and table here.}

