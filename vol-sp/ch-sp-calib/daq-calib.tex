%\section{DAQ Requirements}
%\label{sec:sp-calib-daqreq}

The calibration systems must interface with the DUNE \dword{daq} system, discussed in detail in Chapter~\ref{ch:sp-daq}. 
%Section~\ref{sec:daq}.  
Trigger decisions for physics events are made %done 
hierarchically: \dwords{trigprimitive} are generated from \dword{tpc} and \dword{pds} ``hits'', and these \dwords{trigprimitive} are then used to create \dwords{trigcandidate} which are collections of \dwords{trigprimitive} satisfying selection criteria such as exceeding a threshold number of adjacent collection wire hits, or total collection wire charge recorded, etc. These \dwords{trigcandidate} are passed on to a \dword{mlt} which then makes decisions about whether a given \dword{trigcandidate} is accepted as a detector-wide trigger.  If so, the \dword{mlt} sends trigger commands to the \dword{daqdfo} which in turn passes them to an available \dword{eb} that then requests data from the \dword{fe} readout of the \dword{daq} (servers that host \dword{felix} cards). The management of \dwords{trigdecision}--whether they are generated by candidates from the \dword{tpc}, \dword{pds}, calibrations, or other systems---is done in the \dword{mlt}. 
\fixme{add def to MLT in gloss}

The trigger commands are in the form of absolute time stamps that are used to extract snapshots of the data stored in the \dword{fe} readout buffers. For physics triggers, all \dword{tpc} information for a snapshot of time (roughly twice the drift time, or \SI{5.4}{\milli\s}) are read out, without any additional zero suppression or localization. For calibration events, this approach would create an unmanageable amount of data and, in any case, is unnecessary because calibration events create interactions or tracks at known positions or times or both.

%The primary interface with calibrations will be through the DUNE timing system, which is responsible for synchronization across all subsystems and for providing absolute time stamps t. 

    
    To reduce data volume from calibrations, therefore, calibration systems that can be triggered externally are desirable. Like the distribution of trigger commands to the \dword{fe} readout buffers, the external trigger for a calibration system will take the form of an absolute time stamp. The time stamp is generated by the \dword{mlt}, thus ensuring that (for example) a calibration event does not occur during a candidate supernova burst.  The distribution of these time stamps will be done through the \dword{daq}'s timing and synchronization system. Thus triggerable calibration systems (like the laser or \dword{pns}) will have to be synchronized to the rest of the \dword{daq} system and be capable of accepting time stamps.

There will be differences in the details of how different calibration systems are handled, discussed below. 
           


\begin{dunetable}
[Calibration DAQ summary]
{p{0.2\textwidth}p{0.15\textwidth}p{0.5\textwidth}}
{tab:calib-daq}
{Estimated \dword{daq} Rates per Year per \nominalmodsize for Various Calibration Systems.}   
System & Data Volume (TB/year) & Assumptions  \\ \toprowrule
Ionization Laser System & \num{185} & \num{800}k laser pulses, \num{10}$\times$\num{10}$\times$\SI{10}{\cubic\cm} voxel sizes, a \SI{100}{\micro\s} zero suppression window (lossy readout), and \num{2} times/year  \\ \colhline
Neutron Source System & \num{84} & \num{e6}~neutrons/pulse, \num{1000} neutron captures/m$^{3}$, \num{1300} observed neutron captures per pulse, \num{6}~times/year  \\ \colhline
%Proposed Radioactive Source System & \num{200} & Source rate < \SI{10}{\hertz}; single \dword{apa} readout,  lossless readout; \num{4} times/year   \\ \colhline
\end{dunetable}           
           
\subsubsection{Laser System}

%The proposed laser source is the only practical way to unambiguously measure the electric field vectors within the detector. 
The \efield vector from ionization laser calibration is determined by looking at the deflection of crossing laser tracks within detector voxels. The voxels are currently estimated to be \num{10}$\times$\num{10}$\times$\SI{10}{\cubic\cm}. Because any given laser track
illuminates many such voxels, one laser pulse can be used for several
measurements; essentially, the number that matters is the area of each voxel.
The number of total laser events are estimated to be \num{800000}: about half the rate of cosmic rays and thus nominally a substantial total data volume.


Fortunately, unlike every other event type in the detector, the laser track has both a reasonably well known position and time; thus the trigger command issued to the \dword{fe} buffers can be much narrower than the window used for physics triggers. A \SI{100}{\micro\s} zero suppression window should be wide enough to avoid windowing problems in the induction plane wire deconvolution process.
To ensure that the interesting part of each waveform is recorded, the \dword{daq} will need to know the current position  of the laser, which will be transmitted from the laser system to the \dword{mlt} via the \dword{daq}'s \dword{daqccm}.

From the standpoint of data volume, therefore, the total assuming the \SI{100}{\micro\s} zero-suppression window is
\begin{equation}
\num{800000}/{\rm scan}/\nominalmodsize \times \SI{100}{\micro\s} \times \num{1.5}{\rm Bytes/sample}\times \SI{2}{\mega\hertz}\times \num{384000}~{\rm channels}   = \num{92}~{\rm TB/scan/\nominalmodsize.}   
\end{equation}
If such a calibration scan were done twice a year, then the total annual data volume for the laser is \num{184}~TB/year/\nominalmodsize.

\subsubsection{Pulsed Neutron Source}
%\todo{SG: JW to update this text and the number in the DAQ table 1.3.}
%There are two radioactive sources suggested to provide low-energy calibration data for DUNE: a neutron generator source, and a $\gamma$ source. 

The \dlong{pns} (\dshort{pns}) system creates a burst of neutrons that
%, because of the interesting neutron cross section of argon, 
are captured throughout a large fraction of the total cryostat volume. For triggering and data volume, this is very convenient: the existing scheme of taking \SI{5.4}{\milli\s} of data for each trigger means all these neutrons will be collected in a single \dword{dune} event. Thus, the data volume is simply \num{6.22}~GB times the total number of such pulses, but these are likely to be few: a single burst can produce thousands of neutrons whose $t_0$ is known up to the neutron capture time of \SI{200}{\micro\s} or so.

To trigger the \dword{pns}, the \dword{mlt} will provide a time stamp for the source to fire, and then send a trigger command to the \dword{fe} readout buffers (via the \dword{daqdfo} and \dword{eb}) that will look like a physics trigger command.  The \dword{mlt} itself then tags that trigger command with the expected trigger type (in this case, \dword{pns}).

Typically, a commercial $DD$ neutron generator produces \num{e5} - \num{e8} neutrons/pulse, depending on the adjustable pulse width. The current assumption for neutron yield from the $DD$ generator is \num{e6} neutrons per pulse\footnote{Ideal assumption based on $DD$ generators that produce the most neutron yield with a pulse width less than \SI{100}{\micro\s}. Such $DD$ generators are being developed in laboratories; commercial devices may require further development to reach this level of performance.}. With the current deployment designs in Figure~\ref{fig:PNS_Two_Designs}, approximately \num{1300} neutron captures per $DD$ generator pulse should be observed inside a \nominalmodsize module. As the suggested number for localized energy calibration is \num{1000} neutron captures per \si{\cubic\m}, a total number of \num{4600} pulses would be needed to calibrate a \nominalmodsize module. Assuming two identical \dlong{pns}s operating in synchronization mode, \num{2300} pulses are needed for each calibration run. Therefore, the total data volume per run would be
\begin{equation}
\num{2300}~{\rm Pulses} \times \num{1.5}~{\rm Bytes}\times
\SI{2}{\mega\hertz}\times \SI{5.4}{\milli\s}\times \num{384000}~{\rm channels} = \num{14}~{\rm TB/run}.
\end{equation}
Running the \dword{pns} calibration system every two months would result in a total data volume of \SI{84}{TB} per \nominalmodsize per year and running \num{12} times/year would result in \num{168}~TB/year per \nominalmodsize. This is small compared to the total load on the \dword{daq}, approximately \SI{72}{PByear}.

%\subsubsection{Proposed Radioactive Source System}

%The radioactive source will not be triggerable by the Module Level Trigger.  Rather, it will deliver a tag to the Module Level Trigger and that tag will include a time stamp that can be used by the Module Level Trigger to issue a trigger command to the Front-End Readout.  The trigger command will have a standard readout window size of \SI{5.4}{\milli\s}, but to keep data rates manageable, the command will only be send to Front-End Readout buffers that are expected to be illuminated by the source. The localization of trigger commands thus reduces the data volume by \num{150}, if only one \dword{apa} is read out.

 %Nevertheless, if the rate of such a source is anywhere close to one per \SI{5.4}{\milli\s}, the detector would be running  continuously in the current scheme. Therefore we assume that theinteraction rate in the detector is \SI{10}{\hertz} or less. The tag from the source will likely be much higher than this, because not all $\gamma$s interact in the active \dword{tpc} volume. Thus the radioactive source trigger will be a coincidence in the Module-Level Trigger between a low-energy trigger candidate from the illuminated \dword{apa}, and a source tag with a relevant time stamp.  With this rate, and with localization of events to one \dword{apa}, the total data volume would be

%\begin{equation}
%\num{8}~{\rm hours} \times \num{4}~{\rm FTs} \times %\SI{10}{\hertz} \times \num{1.5}~{\rm Bytes}\times %\SI{2}{\mega\hertz}\times \SI{5.4}{\milli\s}\times \num{2560}~{\rm %channels} = \num{50}~{\rm TB/scan}.
%\end{equation}

%Running this calibration four times/year would yield \num{200}~TB of data in \SI{10}{\kt} per year.


\begin{comment}
%SG: This is not under the scope of this chapter. Needs to be moved to physics. 
\subsubsection{Intrinsic Radioactivity}

Mike Mooney has suggested using the intrinsic \Ar39 as a calibration source. This has many advantages over either of the radioactive
source calibrations, in particular the known level of \Ar39, its uniform distribution in the detector, and the fact that it is always there and therefore integrates correctly over the detector livetime. The difficulty is
that because any individual \Ar39 event's $x$ position is not known
(because there is no $t_0$, the distribution of these events must be used to
make measurements, thus requiring fairly high statistics.

Mooney's proposal is that roughly \num{250000} \Ar39 can provide a \SI{1}{\%} measurement of electron lifetime. (Note that \SI{1}{\%} is a reasonable goal;
if the lifetime and maximum drift time are the same, this results in a \SI{2}{\%} uncertainty on energy scale which would begin to compromise \dword{dune}'s physics program). This number of events is easily obtained with the existing random triggers as well as every other trigger source excluding laser pulses and front-end calibrations.

Like all other parameters that must be calibrated, however, what is not
clear is what the spatial and temporal variations will be in the detector.
Other LAr \dword{tpc}s have performed lifetime calibrations daily (using cosmic rays
primarily), and a pixelization of \SI{1}{\square\m} is not unreasonable, leading to a
need for \num{250000} events for every \si{\square\m} in the detector each day, or about a \SI{1}{\hertz} trigger rate.

In the existing scheme, this would be overwhelmingly the dominant source of data. Thus either the pixelization would need to be reduced (say, to each of the \dword{tpc} volumes) or a zero-suppression scheme would have to be used.
Such a zero-suppression scheme would happen post-trigger---for example, running
random triggers at \SI{1}{\hertz} and based upon that trigger type, zero suppressing
signals. In the current scheme, this would happen in the Event Builder but at \SI{1}{\hertz} the data rate would be too high. To do zero suppression upstream---say in the \dword{apa}-level readout---based on the trigger type will likely require more
hardware resources.
\end{comment}

%\subsection{External Muon Tracker}

%        An External Muon Tracker (EMT) has also been proposed, likely as a scintillator-bar telescope at the front face of the detector. The EMT would be intended to trigger on rock muons and provide a known entry position and direction for these. It is thus the only way to test reconstruction in the DUNE FD for a sample of events in the same energy regime as the beam events.

%        Because the EMT is measuring events that will already be triggered by the \dword{tpc}, the additional data volume comes only from the scintillator counters themselves. Because the only information needed for these events is the time of a hit in each counter, and because only four counters are likely to be hit by each muon (two planes of $x$ and $y$), the additional data rate from the EMT is very small.  If we limit ourselves to just the rock muons and assume that four counters are hit resulting in 4 12-bit words/counter (one charge and one time each, plus the counter ID and a local timestamp, then we get a yearly total data volume of
%\begin{equation}
%735{\rm year/10 ktonne} \times 24~{\rm B/event} = 17.6~{\rm kB/year}   
%\end{equation}