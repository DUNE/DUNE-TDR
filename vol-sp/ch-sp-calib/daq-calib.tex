%\section{DAQ Requirements}
%\label{sec:sp-calib-daqreq}

The calibration systems must interface with the DUNE \dword{daq} system, discussed in detail in Chapter~\ref{ch:daq}.
%Chapter~\ref{ch:sp-daq}. 
%Section~\ref{sec:daq}.  
Trigger decisions for physics events are made %done 
hierarchically: \dwords{trigprimitive} are generated from \dword{tpc} and \dword{pds} ``hits'', and these \dwords{trigprimitive} are then used to create \dwords{trigcandidate} which are collections of \dwords{trigprimitive} satisfying selection criteria such as exceeding a threshold number of adjacent collection wire hits, or total collection wire charge recorded, etc. These \dwords{trigcandidate} are passed on to a \dword{mlt} which then makes decisions about whether a given \dword{trigcandidate} is accepted as a detector-wide trigger.  If so, the \dword{mlt} sends trigger commands to the \dword{daqdfo} which in turn passes them to an available \dword{eb} that then requests data from the \dword{fe} readout of the \dword{daq} (servers that host \dword{felix} cards). The management of \dwords{trigdecision}---whether they are generated by candidates from the \dword{tpc}, \dword{pds}, calibrations, or other systems---is done in the \dword{mlt}. 

The trigger commands are in the form of absolute time stamps that are used to extract snapshots of the data stored in the \dword{fe} readout buffers. For physics triggers, all \dword{tpc} information for a snapshot of time (roughly twice the drift time, or \SI{5.4}{\milli\s}) are read out, without any additional zero suppression or localization. For calibration events, this approach would create an unmanageable amount of data and, in any case, is unnecessary because calibration events create interactions or tracks at known positions or times, or both.


To reduce data volume from calibrations, therefore, calibration systems that can be triggered externally are desirable. Like the distribution of trigger commands to the \dword{fe} readout buffers, the external trigger for a calibration system will take the form of an absolute time stamp. The time stamp is generated by the \dword{mlt}, thus ensuring that (for example) a calibration event does not occur during a candidate supernova burst.  The distribution of these time stamps will be done through the \dword{daq}'s timing and synchronization system. Thus triggerable calibration systems (like the laser or \dword{pns}) will have to be synchronized to the rest of the \dword{daq} system and be capable of accepting time stamps. There will be differences in the details of how different calibration systems are handled, as discussed later in this section. 

%\todo{Jose: check this new paragraph} 
Table~\ref{tab:calib-daq} shows the estimated data volume needs for various calibration systems assuming each system is run twice per year. For the ionization laser system, as noted earlier, a scan of the full detector can take about three days, resulting in a total of about six days or a week per year per \SI{10}{\kt} module. For the \dword{pns} system, as noted later in this section, a single run can take about seven hours;  doing that twice, or even four times, per year will result in a total of about one day per year per \SI{10}{\kt} module. It is expected that once the detector launches into stable operations, the need for full calibration campaign runs will reduce to %say, 
one nominal run per year. %, along with some few 
We also expect some shorter runs may be needed in smaller, targeted regions of the detector, or for detector diagnostic issues. 
           
\begin{dunetable}
[Calibration DAQ summary]
{p{0.2\textwidth}p{0.15\textwidth}p{0.5\textwidth}}
{tab:calib-daq}
{Estimated data volume needs per year per \nominalmodsize for various calibration systems.}   
System & Data Volume (TB/year) & Assumptions  \\ \toprowrule
Ionization Laser System & \num{184} & \num{800}k laser pulses, \num{10}$\times$\num{10}$\times$\SI{10}{\cubic\cm} voxel sizes, a \SI{100}{\micro\s} zero suppression window (lossy readout), and \num{2} times/year  \\ \colhline
Neutron Source System & \num{144} & \num{e5}~neutrons/pulse, \num{100} neutron captures/m$^{3}$, \num{130} observed neutron captures per pulse, \num{2}~times/year  \\ 
%Proposed Radioactive Source System & \num{200} & Source rate < \SI{10}{\hertz}; single \dword{apa} readout,  lossless readout; \num{4} times/year   \\ \colhline
\end{dunetable}           
           
\subsubsection{Laser System}


The \efield vector from ionization laser calibration is determined by looking at the deflection of crossing laser tracks within detector voxels.  Because any given laser track illuminates many such voxels, one laser pulse can be used for several measurements; essentially, what matters is how many voxels it takes to cover three walls of a given drift volume -- \dword{cpa}, bottom and end-wall \dword{fc}, taking into account that we divide that volume by \num{4} because of beam coverage.

Considering a small voxel size of  \num{10}$\times$\num{10}$\times$\SI{10}{\cubic\cm}, the total number of independent track directions is estimated to be \num{800000}: about half the rate of cosmic rays and thus nominally a substantial total data volume. 
However, with the specification voxel size of \num{30}$\times$\num{30}$\times$\SI{30}{\cubic\cm}, that number would be \num{27} times smaller, so that would allow a larger number of tracks per direction. Keeping to the overall estimate of \num{800000} tracks per scan, the choice of voxel granularity and track statistics per direction can be made until the commissioning period.

Fortunately, unlike every other event type in the detector, the laser track has both a reasonably well known position and time; thus the trigger command issued to the \dword{fe} buffers can be much narrower than the window used for physics triggers. A \SI{100}{\micro\s} zero suppression window should be wide enough to avoid windowing problems in the induction plane wire deconvolution process.
To ensure that the interesting part of each waveform is recorded, the \dword{daq} will need to know the current position  of the laser, which will be transmitted from the laser system to the \dword{mlt} via the \dword{daqccm}.

From the standpoint of data volume, therefore, the total assuming the \SI{100}{\micro\s} zero-suppression window is
\begin{equation}
\num{800000}/{\rm scan}/\nominalmodsize \times \SI{100}{\micro\s} \times \num{1.5}{\rm Bytes/sample}\times \SI{2}{\mega\hertz}\times \num{384000}~{\rm channels}   = \num{92}~{\rm TB/scan/\nominalmodsize.}   
\end{equation}
If such a calibration scan were done twice a year, then the total annual data volume for the laser is \num{184}~TB/year/\nominalmodsize and four times a year would result in \num{368}~TB/year/\nominalmodsize

\subsubsection{Pulsed Neutron Source}

The \dlong{pns} (\dshort{pns}) system creates a burst of neutrons that
%, because of the interesting neutron cross section of argon, 
are captured throughout a large fraction of the total cryostat volume. For triggering and data volume, this is very convenient: the existing scheme of taking \SI{5.4}{\milli\s} of data for each trigger means all these neutrons will be collected in a single \dword{dune} event. Thus, the data volume is simply \num{6.22}~GB times the total number of such pulses, but these are likely to be few: a single burst can produce thousands of neutrons whose $t_0$ is known up to the neutron capture time of \SI{200}{\micro\s} or so.

To trigger the \dword{pns}, the \dword{mlt} will provide a time stamp for the source to fire, and then send a trigger command to the \dword{fe} readout buffers (via the \dword{daqdfo} and \dword{eb}) that will look like a physics trigger command.  The \dword{mlt} itself then tags that trigger command with the expected trigger type (in this case, \dword{pns}).

Typically, a commercial $DD$ neutron generator produces \num{e5} - \num{e8} neutrons/pulse, depending on the adjustable pulse width. 
The current assumption for neutron yield from the $DD$ generator is \num{e5} neutrons per pulse\footnote{Realistic assumption based on commercially available $DD$ generators that produce the most neutron yield with a pulse width less than \SI{100}{\micro\s}. 
$DD$ generators with higher neutron yield are being developed in laboratories; commercial devices may require further development to reach a higher level of performance.}. 
With the current baseline deployment design in Figure~\ref{fig:PNS_Moderator_largeformat}, approximately \num{130} neutron captures per $DD$ generator pulse should be observed inside a \nominalmodsize module. As shown in Figure~\ref{fig:PNS_ncapDistribution_two_sources}, the deployment of two large format neutron sources at the corner human access ports could approximately provide calibration for about half of the total \dword{tpc} volume (\SI{30}{\kt}). 
As the suggested number for localized energy calibration is \num{100} neutron captures per \si{\cubic\m}, a total number of \num{2300} pulses would be needed to calibrate regions under high neutron coverage. Assuming two identical \dlong{pns}s operating in synchronization mode, \num{1150} triggers are needed for each calibration run. Therefore, the total data volume per run would be
\begin{equation}
\num{1150}~{\rm Triggers} \times \num{1.5}~{\rm Bytes}\times
\SI{2}{\mega\hertz}\times \SI{5.4}{\milli\s}\times \num{384000}~{\rm channels} = \num{7.2}~{\rm TB/run}.
\end{equation}
The recommended trigger rate of the \dword{pns} system is \SI{0.5}{\hertz} which is limited by the bandwidth of the DAQ event builder. Assuming that the spatial distribution of the neutron capture is near-uniform for the regions that are covered by the two large format neutrons sources, the operation time per calibration run would be 40 minutes.   
Running the \dword{pns} calibration system twice a year would result in a total data volume of \SI{14.4}{TB} per \nominalmodsize per year. 
For realistic neutron capture distribution that is non-uniform, we expect to operate the \dword{pns} system for a period of 10 times longer than that under the ideal assumption (7.2 TB/run). As a consequence, the data size per calibration run would be 72 TB/run and running the \dword{pns} calibration twice a year would result in a total data size of \num{144}~TB/year/\nominalmodsize and four times a year results in \num{288}~TB/year/\nominalmodsize.






