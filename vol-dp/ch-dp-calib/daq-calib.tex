%\section{DAQ Requirements}
%\label{sec:sp-calib-daqreq}
%\fixme{JM/SG made edits. Josh K. to verify and sign off, especially the updated rates and assumptions there.}

The calibration systems must interface with the \dword{dune} \dword{daq} system, discussed in detail in %\dpchdaq 
Chapter~\ref{ch:dp-daq} of this \dword{tdr}.


Trigger decisions for physics events are made %done 
hierarchically: \dwords{trigprimitive} are generated from %\dword{tpc} 
\dword{crp} and \dword{pds} ``hits'', and these \dwords{trigprimitive} are then used to create \dwords{trigcandidate}, which are collections of \dwords{trigprimitive} satisfying selection criteria such as exceeding a threshold number of adjacent 
%collection wire 
\dword{crp} hits, or total 
%collection wire 
charge recorded, as well as other criteria. These \dwords{trigcandidate} are passed on to a \dword{mlt}, which then makes decisions about whether a given \dword{trigcandidate} is accepted as a detector-wide trigger.  If so, the \dword{mlt} sends trigger commands to the \dword{daqdfo}, which in turn passes them to an available \dword{eb} that then requests data from the \dword{fe} readout of the \dword{daq} (servers that host \dword{felix} cards). The management of \dwords{trigdecision}---whether they are generated by candidates from the \dword{tpc}, \dword{pds}, calibrations, or other systems---is done in the \dword{mlt}. 

The trigger commands are in the form of absolute time stamps that are used to extract snapshots of the data stored in the \dword{fe} readout buffers. For physics triggers, all \dword{tpc} information for a snapshot of time
%(roughly twice the drift time, or \SI{5.4}{\milli\s})
(\SI{16.4}{\milli\s}) %\todo{SG: readout time updated to 16.4 ms for DP. JK to sign off} 
are read out, without any additional zero suppression or localization. For calibration events, this approach would create an unmanageable amount of data and, in any case, is unnecessary because calibration events create interactions or tracks at known positions or times, or both.


    To reduce data volume from calibrations, therefore, calibration systems that can be triggered externally are desirable. Like the distribution of trigger commands to the \dword{fe} readout buffers, the external trigger for a calibration system will take the form of an absolute time stamp. The time stamp is generated by the \dword{mlt}, thus ensuring that (for example) a calibration event does not occur during a candidate supernova burst.  
    
    The distribution of these time stamps will be done through the \dword{daq}'s timing and synchronization system. Thus triggerable calibration systems (like the laser or \dword{pns}) will have to be synchronized to the rest of the \dword{daq} system and be capable of accepting time stamps. There will be differences in the details of how different calibration systems are handled, as discussed later in this section. 
    
     Table~\ref{tab:calib-daq} shows the estimated data volume needs for various calibration systems assuming each system is run twice per year. For the ionization laser system, as noted earlier, a scan of the full detector can take about two days, resulting in a total of about four days per year per \SI{10}{\kt} module. For the \dword{pns} system, as noted later in this section, a single run can take about seven hours;  doing that twice, or even four times, per year will result in a total of about one day per year per \SI{10}{\kt} module. It is expected that once the detector launches into stable operations, the need for full calibration campaign runs will reduce to one nominal run per year. We also expect some shorter runs may be needed in smaller, targeted regions of the detector, or for detector diagnostic issues. 
           
\begin{dunetable}
[Calibration DAQ summary]
{p{0.2\textwidth}p{0.15\textwidth}p{0.5\textwidth}}
{tab:calib-daq}
{Estimated \dword{daq} rates per year per \SI{10}{\kt} for various calibration systems.}   
System & Uncompressed Data Volume (TB/year) & Assumptions  \\ \toprowrule
Ionization Laser System & \num{37} & \num{400}k laser pulses, \num{10}$\times$\num{10}$\times$\SI{10}{\cubic\cm} voxel sizes, a \SI{100}{\micro\s} zero suppression window (lossy readout), \num{2} times/year  \\ \colhline
Neutron Source System & \num{170} & \num{e5}~neutrons/pulse, \num{100} neutron captures/m$^{3}$, \num{130} observed neutron captures per pulse, \num{2}~times/year  \\ 
\end{dunetable}           
           
\subsubsection{Laser System}

%The proposed laser source is the only practical way to unambiguously measure the electric field vectors within the detector. 
The \efield vector from ionization laser calibration is determined by looking at the deflection of crossing laser tracks within detector voxels. The voxels are currently estimated at \num{10}$\times$\num{10}$\times$\SI{10}{\cubic\cm}. Because any given laser track
illuminates many such voxels, one laser pulse can be used for several
measurements; essentially, the number that matters is the area of each voxel.
The number of total laser events are estimated to be \num{400000}
%: about half the rate of cosmic rays 
and thus nominally produces a substantial total volume of data.
However, with the specification voxel size of \num{30}$\times$\num{30}$\times$\SI{30}{\cubic\cm}, that number would be \num{27} times smaller, so that would allow a larger number of tracks per direction. Keeping to the overall estimate of \num{400000} tracks per scan, the choice of voxel granularity and track statistics per direction can be made until the commissioning period.

Fortunately, unlike every other event type in the detector, the laser track has both a reasonably well known position and time; thus the trigger command issued to the \dword{fe} buffers can be much narrower than the window used for physics triggers. A \SI{100}{\micro\s} zero suppression window should be wide enough to avoid windowing problems in the 
%induction plane wire \todo{SG:this sentence needs to be updated for DP}
signal deconvolution process. To ensure that the interesting part of each waveform is recorded, the \dword{daq} will need to know the current position  of the laser, which will be transmitted from the laser system to the \dword{mlt} via the \dword{daqccm}.


From the standpoint of data volume, therefore, the total, assuming the \SI{100}{\micro\s} zero-suppression window, is
\begin{equation}
\num{400000}/{\rm scan}/\SI{10}{\kt} \times \SI{100}{\micro\s} \times \num{1.5}{\rm Bytes/sample}\times \SI{2}{\mega\hertz}\times \dpnumcrpch~{\rm channels}   = \num{18.4}~{\rm TB/scan/\SI{10}{\kt}.}   
\end{equation}

If such a calibration scan were done twice a year, then the total annual data volume for the laser is approximately \num{37}~TB/year/\SI{10}{\kt}.


\subsubsection{Pulsed Neutron Source}

The \dword{pns} (\dshort{pns}) system creates a burst of neutrons that
%, because of the interesting neutron cross section of argon, 
are captured throughout a large fraction of the total cryostat volume. For triggering and data volume, this is very convenient: the existing scheme of taking \SI{16.4}{\milli\s} of data for each trigger means all these neutrons will be collected in a single \dword{dune} event.%\todo{SG: this requires updating since DP readout is not 5.4 ms} 
Thus, the data volume is simply \num{6.22}~GB times the total number of such pulses, but these are likely to be few: a single burst can produce thousands of neutrons whose $t_0$ is known up to the neutron capture time of \SI{200}{\micro\s} or so.

To trigger the \dword{pns}, the \dword{mlt} will provide a time stamp for the source to fire and then send a trigger command to the \dword{fe} readout buffers (via the \dword{daqdfo} and \dword{eb}) that will look like a physics trigger command.  The \dword{mlt} itself then tags that trigger command with the expected trigger type (in this case, \dword{pns}).

Typically, a commercial $DD$ neutron generator produces \num{e5} - \num{e8} neutrons/pulse, depending on the adjustable pulse width. The current assumption for neutron yield from the $DD$ generator is \num{e5} neutrons per pulse\footnote{Realistic assumption based on commercially available $DD$ generators that produce the most neutron yield with a pulse width less than \SI{100}{\micro\s}. 
$DD$ generators with higher neutron yield are being developed in laboratories; commercial devices may require further development to reach a higher level of performance.}. 
With the current baseline deployment design in 
Figure~\ref{fig:PNS_Two_Designs}, approximately \num{130} neutron captures per $DD$ generator pulse should be observed inside a \nominalmodsize module. 
As the suggested number for localized energy calibration is \num{100} neutron captures per \si{\cubic\m}, a total number of \num{2300} pulses would be needed to calibrate regions under high neutron coverage. Assuming two identical \dlong{pns}s operating in synchronization mode, \num{1150} triggers are needed for each calibration run. Therefore, the total data volume per run would be
\begin{equation}
\num{1150}~{\rm Triggers} \times \num{1.5}~{\rm Bytes}\times
\SI{2}{\mega\hertz}\times \SI{16.4}{\milli\s}\times \dpnumcrpch~{\rm channels} = \num{8.5}~{\rm TB/run}.
\end{equation}
The recommended trigger rate of the \dword{pns} system is \SI{0.5}{\hertz} which is limited by the bandwidth of the \dword{daq} event builder.  Assuming that the spatial distribution of the neutron capture is near-uniform for the regions that are covered by the two large format neutron sources, the operation time per calibration run would be 40 minutes.   
Running the \dword{pns} calibration system twice a year would result in a total data volume of \SI{17}{TB} per \nominalmodsize per year. 
For realistic neutron capture distribution that is non-uniform, based on corner human-access port locations, we expect to operate the \dword{pns} system for a period ten times longer than we would under the ideal assumption (\SI{8.5}{TB/run}). As a consequence, the data size per calibration run would be \SI{85}{TB/run} and running the \dword{pns} calibration twice a year would result in a total data size of \num{170}~TB/year/\nominalmodsize and four times a year results in \num{340}~TB/year/\nominalmodsize. However, depending on the final location chosen for the \dword{pns} ports, such a high data volume might not be necessary, since locations closer to the middle have better coverage.



\begin{comment}
%SG: This is not under the scope of this chapter. Needs to be moved to physics. 
\fixme{I did go ahead and edit this, but apparently it goes elsewhere in the manuscript.}
\subsubsection{Intrinsic Radioactivity}

Mike Mooney has suggested using the intrinsic \Ar39 as a calibration source. This has many advantages over either of the radioactive
source calibrations, in particular the known level of \Ar39, its uniform distribution in the detector, and the fact that it is always there and therefore integrates correctly over the detector lifetime. The difficulty is
that, because any individual \Ar39 event's $x$ position is not known
because there is no $t_0$, the distribution of these events must be used to
make measurements, thus requiring fairly high statistics.

Mooney's proposal is that roughly \num{250000} \Ar39 can provide a \SI{1}{\%} measurement of electron lifetime. (Note that \SI{1}{\%} is a reasonable goal;
if the lifetime and maximum drift time are the same, this results in a \SI{2}{\%} uncertainty on energy scale, which would begin to compromise \dword{dune}'s physics program). This number of events is easily obtained with the existing random triggers as well as every other trigger source excluding laser pulses and front-end calibrations.

Like all other parameters that must be calibrated, however, what is not
clear is what the spatial and temporal variations will be in the detector.
Other \dword{lar} \dword{tpc}s have performed lifetime calibrations daily (using cosmic rays
primarily), and a pixelization of \SI{1}{\square\m} is not unreasonable, leading to a
need for \num{250000} events for every \si{\square\m} in the detector each day, or about a \SI{1}{\hertz} trigger rate.

In the existing scheme, this would be overwhelmingly the dominant source of data. Thus either the pixelization must be reduced (say, to each of the \dword{tpc} volumes) or a zero-suppression scheme must be used.
Such a zero-suppression scheme would happen post-trigger (for example, running random triggers at \SI{1}{\hertz} and based upon that trigger type, zero suppressing
signals). In the current scheme, this would happen in the event builder, but at \SI{1}{\hertz}, the data rate would be too high. To do zero suppression upstream (perhaps in the \dword{apa}-level readout) based on the trigger type will likely require more
hardware resources.
\end{comment}

