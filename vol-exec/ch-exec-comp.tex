\chapter{Computing in DUNE}
\label{ch:exec-comp}

\textit{This chapter briefly describes the DUNE computing model, which touches on all elements of the DUNE near and far detectors and their physics programs.  More detailed aspects of the model may be found in Appendix~\ref{appx:comp-roles} of this TDR volume.  DUNE will produce a compete technical design report for computing over the next two years.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Executive Summary}
\label{ch:exec-comp-es}


The \dword{dune} experiment is preparing to commission the first \nominalmodsize fiducial mass \dword{lartpc} module between 2024 and 2026 with a long data-taking run, the number of module will increase to four between 2026 and 2036 and beyond.  An active prototyping program is already in place and has had  a short test beam run in 2018 at \dword{cern}.  These tests used  a \SI{700}{t}, 15,360 channel prototype \dword{tpc} with \dword{sp} readout.  Tests of a \dword{dp} detector of similar size are scheduled for mid-2019.   The \dword{dune} experiment has already  benefited greatly from these initial tests.  The collaboration has recently formed a formal \dword{csc}, with significant participation by European institutions and interest from groups in Asia, to develop common software and computing and to formalize resource contributions.

The consortium resource model benefits from existing \dword{osg}  and \dword{wlcg} infrastructure developed for the \dword{lhc} and broader \dword{hep} community.  \dword{dune} is already using global resources for simulating and analyzing  \dword{pdsp} data.  Several European institutions are part of this resource pool and are making significant contributions to the \dword{pdsp} and \dword{pddp} programs.  We expect this global computing consortium to grow and evolve as we move towards gathering data from the full \dword{dune} detector in the 2020s.

The long-term \dword{dune} science program should produce raw data volumes similar in scale to the data volumes that current \dword{lhc} Run-2 experiments have already handled successfully.  Baseline predictions for the \dword{dune} data, depending on actual detector performance and noise levels, are $\sim\,$\SI{30}{PB} of raw data per year.  These data, with simulations and derived analysis samples, must be available to all collaborating institutions.  We anticipate that institutions worldwide will be both contributors and end-users of storage and CPU resources for \dword{dune}.




\dword{dune} starts with considerable infrastructure in place for international computing collaboration thanks to the \dword{lhc} program.  Additional large non-\dword{lhc} experiments,  such as \dword{lsst}, the \dword{belleii} B-factory experiment, and \dword{dune}  will enter operation over the next decade and must use and expand upon this model for international cooperation.  Organizing the broader HEP community is formalized through the \dword{hsf}~\cite{Alves:2017she}.  The \dword{hsf} is an organization of interested parties working to use the extensive knowledge gained over the past two decades to anticipate the needs of experiments   over the next two decades to develop a sustainable computing landscape for the HEP community.  The \dword{hsf} white papers and roadmaps emphasize common tools and infrastructure as the underpinnings of this landscape.

\dword{dune}'s computing strategy heavily leverages this model of common tools and infrastructure and features data movement and storage, job control and monitoring, accounting, and authentication that both use and contribute to this global community.   \dword{dune} recognizes that other large-scale experiments have similar needs and will encounter similar issues, thus driving worldwide cooperation on common tools as the most cost-effective way to fulfill the scientific missions of the experiments.  \dword{dune} pilot programs already use this model.  Most recently in data management and storage, \dword{fermilab}, \dword{cern}, Rutherford Appleton Laboratory, and other academic institutions in the %United Kingdom ah
UK are collaborating on adapting and using the \dword{rucio} data management systems~\cite{Barisits:2019fyl}  to serve as the core data management system for \dword{dune}.

%Examples of 
This protoculture of international collaboration within \dword{dune} %were 
was demonstrated during the 2018 test beam run of the \dword{pdsp} detector  at \dword{cern}.  During this run, % the \dword{sp} ah
\dword{pdsp} produced raw data at rates of up to \SI{2}{GB/s}.  These data were transferred and stored in the archive facilities at \dword{cern} and \dword{fermilab}, and replicated at sites in the UK and Czech Republic.  In a more recent commissioning test for the \dword{pddp} detector, similar rates %have been 
were achieved to \dword{cern}, \dword{fermilab} and the CCIN2P3 computer center in Lyon, France.

In total, \SI{1.8}{PB} of raw data were produced during the ten week test beam run, mimicking, within a factor of two, expected data rates and volumes from the initial running of the \dword{fd} complex.  The prototype run was used to examine and test the scalability of existing and proposed computing infrastructure and to establish operational experience within the institutions that have expressed interest in the development and construction of the \dword{dune} computing environment.  Our planning is based heavily on the measurements and information gained from the \dword{protodune} experience.   These measurements are proofs-of-concept for many of the systems, and their behavior can be extrapolated to the projected levels needed for the full \dword{dune} experiment. 


The \dword{protodune} experience has highlighted significant technical challenges that will need to be overcome for the full experiment by 2024. Among the most significant will be  1) the design of \dword{dune} specific systems capable of integrating the large suite of ancillary data - configurations, calibrations, shower libraries - with the main \dword{tpc} datastream, 2) the extreme potential size of some interactions, notably supernova bursts, which will overwhelm conventional processors and 3) responding to the continuing evolution of computing architectures and infrastructure over the next decade. These are area unique to \dword{dune} where the limiting factor will be human effort. 

In summary, \dword{dune}'s computing strategy must be global--working with partners worldwide--and collaborative because many of the computational challenges we face are also %those facing ah
faced by similar experiments.  We are extremely fortunate to have the ProtoDUNE test data to exercise our computing infrastructure and to develop algorithms for  full \dword{dune} operations but know that  significant and interesting challenges lie ahead. 
 
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Computing Consortium}
\subsection{Overview}
\label{ch:exec-comp-ovr}

The mission of the \dword{dune} %computing consortium (CSC) ah
\dword{csc} is to facilitate the acquisition, processing, and analysis of both detector data and supporting simulations for the %\dword{dune} ah
experiment.  This mission must extend over all of the primary physics drivers for the experiment and must do so both cost effectively and securely. The \dword{csc} provides the bridge between  online \dword{daq} and monitoring systems and the different physics groups who develop high-level algorithms and analysis techniques to perform measurements with the \dword{dune} data and simulations. The \dword{csc} works with collaborating institutions to identify and provide computational and storage resources.  %They provide ah
It provides the software and computing infrastructure in the form of analysis frameworks, data catalogs, data transport systems, database infrastructure, code distribution mechanisms, production systems, and other support services essential for recording and analyzing the data and simulations. 

The \dword{csc} works with national agencies and major laboratories to negotiate use and allocation of computing resources.  This work includes support for near-term and R\&D efforts %like ah 
such as \dword{protodune} runs, and extends to the design, development, and deployment of the \dword{dune} computing model and its requisite systems. 
These designs include evaluating major software infrastructure systems to determine their usefulness %for 
in meeting the \dword{dune} physics requirements.   These evaluations should identify opportunities to adopt or adapt existing technologies and to engage in collaborative ventures with HEP experiments outside of \dword{dune}. 

\fixme{this needs a different heading. AH}

At first glance,  the \dword{dune} CPU and storage needs %are ah
appear modest %on the scale of ah
relative to the projected rates and needs for the high-luminosity \dword{lhc} experiments.  
However, the  beam structure, event sizes, and analysis methodologies make \dword{dune} very unlike collider experiments %in ah
as regards event processing needs and projected computational budgets. \fixme{What are the features of these items that are different? AH} The large \dword{dune} event sizes present a novel technical challenge when data processing and analysis are mapped onto  current and planned computing facilities. \fixme{previous sentence needs clarification once we understand the novel aspects. AH} %In particular, the advent of high-performance computing systems optimized for parallel processing of large data arrays presents \dword{dune} with a potential advantage, as our event structure is more suited to those architectures than conventional tracker-based HEP data. AH
The advent of high-performance computing systems optimized for parallel processing of large data arrays is a great advantage for \dword{dune}. These architectures suit \dword{dune}'s event structure quite well, more closely than they do conventional tracker-based HEP data. \fixme{we need the background to understand why. AH}

Neutrino oscillation analysis and parameter extraction also present %novel computational 
challenges.  \fixme{what's novel about them? AH}

%These novel features of \dword{dune} data ah
\dword{dune} will require significant effort to adapt to the emerging  %available 
global computing resources that % available to the experiment.ah 
%These global resources ah
will  likely be both more heterogeneous in computational capabilities (e.g., featuring CPU, GPU, and other advanced technologies) and more diverse in topological architectures and provisioning models.  The \dword{dune} \dword{csc} must %address these issues of diversity and architecture ah
be ready to fully exploit these global resources %available ah 
after 2026 and enable all collaborators to access the data and perform the scientific mission of the experiment.  



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Resources and Governance}
\label{ch:exec-comp-gov}

%The computing and software group is now a \dword{dune} consortium. ah
The \dword{csc} was formed from an earlier ad-hoc \dword{dune} computing and software group. % in \fixme{date?}
Reference~\cite{bib:docdb12751} describes the governance structure for the consortium.  The consortium coordinates effort across the collaboration, but funding comes from collaborating institutions, laboratories, and national funding agencies. %Aside from a small fraction of the consortium leadership, it is not supported by \dword{dune} or \dword{lbnf} project funds.  \fixme{lbnf?}

The %consortium 
\dword{csc} has an overall consortium leader %. The consortium leader 
who is responsible for the subsystem deliverables and represents the consortium in the overall \dword{dune} collaboration.
In addition, technical leads act as overall project managers for the consortium. The technical leads report to the overall consortium leader.
\dword{csc} has both a host laboratory technical lead to coordinate between the \dword{dune} project and Fermilab, the host laboratory, and an international  technical lead to coordinate with other entities.
At least one of the three leadership roles should be held by a non-US scientist. 
Other roles are currently filled on a voluntary basis by the consortium management.  A more formal structure for institutional contributions and commitments is being constructed. 


\begin{figure}[htp]
\centering
\includegraphics[height=3in]{graphics/comp_Org_Chart.pdf}
\caption[Organization chart for current \dshort{csc}]{Organization chart for current \dword{csc}. }
\label{fig:ch-exec-comp-org}
\end{figure}

\subsection{Scope of the Consortium}
The \dword{csc}'s focus is the hardware and software infrastructure  for offline computing.  Responsibility for development of algorithms  resides within the physics groups, %while ah
and online systems at experimental sites are governed by the \dword{daq} and \dword{cisc} consortia. The \dword{csc} plays a coordinating role through the definition of interfaces, coding standards, and training. All groups coordinate closely to ensure that the full chain of data acquisition, processing, and analysis %works
functions properly. Formal interfaces with the \dword{daq} and controls groups are described in~\cite{bib:docdb7123,bib:docdb7126}. % Docdb 7123 (DAQ)\cite{bib:docdb7123} and Docdb 7126 (CISC)\cite{bib:docdb7126}.

The \dword{csc} operates at two levels: at the hardware level, where generic resources can be provided as in-kind contributions to the collaboration, and at the human level, where individuals and groups help develop common software infrastructure.  The   technology for hardware contributions (grid CPU and storage) exists and was exercised during the \dword{pdsp} data run and its associated %"associated" added by ah
simulation and reconstruction. Highlights of that effort are discussed below and in \physchtools{}. % the Tools and Methods section of the Physics volume.  



\begin{figure}[htp]
\centering
\includegraphics[height=3in]{graphics/comp-ComputingLastYear.png}
\caption[CPU wall-time from July 2018 to July 2019]{CPU wall-time from July 2018 to July 2019, the 1st peak shows  ProtoDUNE-SP reconstruction while the second is dominated by data analysis and ProtoDUNE-DP simulation. A total of 31 million wall-hours were delivered with 24 M-hrs coming from Fermilab.  }
\label{fig:ch-exec-comp-cpupie}
\end{figure}


\subsection{Hardware Infrastructure}
As illustrated in Figure~\ref{fig:ch-exec-comp-cpupie}, the \dword{dune} collaboration has already used substantial global resources through the \dword{wlcg} and \dword{osg} mechanisms. As the experiment evolves over the next five years, institutions and collaborating nations will be asked to formally pledge resources (both CPU and storage), and those resources will be accounted for and considered in-kind contributions to the collaboration.  A   computing resources board  is being set up to administer this process and liaise with national resource providers. 

Several international partners are already contributing substantially to CPU resources, and we continue to  integrate additional large national facilities. Most CPU resources are opportunistic, but \dword{fermilab} and \dword{cern} have committed several thousand cores and several PB of disk. Additionally,  \dword{dune} has been one of the first beneficiaries of the UK's IRIS project to provide computing for astronomy and particle physics.  
We are working with \dword{osg} and \dword{wlcg} to integrate reporting mechanisms for CPU utilization so that accurate monitoring of hardware contributions will be in place for the second \dword{protodune} run in 2021-2022 and the buildup to data taking in the mid 2020's. 


\begin{dunetable}
[DUNE CSC institutions as of July 2019]{lll}{tab:exec-comp-consortium}{DUNE Computing and Software Consortium members as of July 2019.}%-- indicates sites not yet integrated into production computing. }%\rowtitlestyle
Institution& Country \\\colhline%& Integrated\\
KISTI&Korea\\\colhline %&--\\
TIFR  & India \\\colhline%& in process \\
Nikhef&NL\\\colhline%&Yes\\
Edinburgh&UK\\\colhline%&Yes\\
Manchester&UK\\\colhline%&Yes\\
RAL/STFC&UK\\\colhline%&Yes\\
CIEMAT/PIC&ES\\\colhline
Argonne&USA\\\colhline%&Yes\\
BNL&USA\\\colhline%&Yes\\
Cincinnati&USA\\\colhline%& Yes\\
Colorado State&USA\\\colhline%& Yes\\
CU Boulder&USA\\\colhline%&Yes\\
Fermilab&USA\\\colhline%& Yes \\
Florida &USA\\\colhline%& Yes\\
LBNL&USA\\\colhline%&Yes\\
Minnesota&USA\\\colhline%&Yes\\
Northern Illinois Univ.&USA\\\colhline%&USA& --\\
Notre Dame&USA\\\colhline%&Yes\\
Oregon State University&USA\\\colhline%&Yes\\
Tennessee&USA\\\colhline%&--\\
Texas, Austin&USA\\%&--\\
\end{dunetable}

\subsection{Personnel}


Development of a  dedicated \dword{dune} computing team, responsible for operations and development of new tools specific to DUNE's needs is ongoing. 
Figure~\ref{fig:ch-exec-comp-org} shows the current organization.  Very few of these individuals are full time on DUNE, and we largely rely on use of common tools and techniques shared with other, smaller, experiments at \dword{cern} and \dword{fnal}. In particular, DUNE currently operates as one of several ``intensity frontier'' experiments at \dword{fnal}, with access to substantial shared resources but very few personnel assigned specifically to DUNE.  As one of our basic design tenets is cooperation and reuse of tools with the broader community, a significant shared component is indeed useful, but a small team of dedicated personnel still needs to be built. 
The full DUNE software and computing effort will be much larger in scale and needs to begin serious construction and operations well before commissioning begins at \dword{surf}. The unique DUNE data footprint and anticipated evolution in processor technologies will necessitate major efforts to construct and operate the computing infrastructure that we will need for the full experiment.

Personnel resources similar in scale to that for \dword{lhcb} and \dword{belleii}, which have a similar collaboration size and international scope and around 20 \dword{fte} dedicated to core software and computing, will be needed.  
Much of the high-level algorithm development will be done by collaboration scientists, but a dedicated core group of experts with strong programming and project management skills will be needed to build and operate the core software infrastructure for the experiment.  We have used the \dword{lhcb} organization structure for a first estimate of our future personnel requirements.


Appendix \ref{comp-roles} describes  computing personnel activities in detail.  In summary, around 20 total  \dword{fte} are needed, with  ten \dword{fte} for software development to create and maintain the core software necessary to run \dword{dune} algorithms and the distributed software infrastructure.  Some of this effort will be shared with other collaborations and \dword{hsf}/\dword{wlcg} projects, but in return, DUNE will need to make substantive contributions to those common efforts. In addition to development effort,%there are 
specific operational roles such as data manager, code librarian, user support, and management %that 
will require personnel dedicated specifically to DUNE computing. Based on \dword{lhcb} experience, we have identified ten such roles 
requiring full-time-equivalent \dword{fte} of 0.5 to 2.0.  These roles can be filled by experienced DUNE collaborators or computing professionals and their contributions to the experiment should be  recognized. 



The \dword{csc} is instituting a series of workshops, starting with one called ``Data Model and Infrastructure'' in the summer and fall of 2019, to set the scope of the subprojects in preparation for a formal computing \dword{tdr}. Table~\ref{tab:comp-milestones} gives a draft timeline for the computing project.

\begin{dunetable}[Milestones for DUNE computing development]{l l r}{tab:comp-milestones}{Milestones for DUNE computing development.  Data volumes assume 15 PB/year of compressed raw data starting in 2024.}
Year	&	Activity	&	integrated data, PB	\\ \toprowrule%
2018	&  	&	10	\\ \colhline
	& 	\dshort{pdsp} beam run	&	\\ \colhline
2019	&		&	19	\\ \colhline%
	&	\dshort{pdsp} processing	&		\\ \colhline%
	&	\dshort{pddp} commissioning and data taking	&		\\ \colhline%
	&	Develop resource model	&		\\ \colhline%
	&	Develop high level task list	&		\\ \colhline%
2020	&		&	21	\\ \colhline%
	&	Continue \dshort{protodune} processing/operations	&		\\%
	&	Formalize international resource model	&		\\ \colhline%
	&	Build operations team	&		\\ \colhline%
	&	Evaluate data and computing models	&		\\ \colhline%
	&	Data base design for hardware	&		\\ \colhline%
2021	&		&	25	\\ \colhline%
%	&	%TDR	&		\\ \colhline%
	&	Produce Computing TDR	&		\\ \colhline%
	&	Framework modifications for HPC 	&	\\ \colhline%	
	&	Data base design for conditions/configuration	&		\\ \colhline%
2022	&		&	39	\\ \colhline%
	&	\dshort{protodune} second beam run	&		\\ \colhline%
	&	Begin large scale purchases for FD commissioning	&		\\ \colhline%
2023	&		&	43	\\ \colhline%
	&	Reconstruct/analyze \dshort{protodune} results	&		\\ \colhline%
	&	Continue \dshort{protodune} processing/operations	&		\\ \colhline%
	&	Support FD commissioning	&		\\ \colhline%
	&	Conditions and configuration data fully integrated	&		\\ \colhline%
	&	Acquire storage for first year of data from one module	&		\\ \colhline%
2024	&		&	66	\\ \colhline%
	&	First real data from one FD module	&		\\ \colhline%
	&	Full operations team in place	&		\\ \colhline%
	&	Data analysis challenges	&		\\ \colhline%
2025	&		&	88	\\ \colhline%
	&	Complete provisioning of hardware/storage for first beam run	&		\\ \colhline%
2026	&		&	111	\\ \colhline%
	&	First beam run with two modules 	&	 	\\%
	\end{dunetable}

\subsection{Resource Contributions}


A formal resource funding model is being developed through the \dword{csc} Resource Board. Present thinking is that collaborating countries will be expected to contribute to the computing physical resource and operational duties (e.g. shifts) on a fair-share basis that will be developed in consultation with the full DUNE collaboration.  Core software development effort is expected to come from \dword{csc} members.  Contributions will be a mix of CPU resources, storage and personnel with the mix tailored to the resources and capabilities of the county/institution. To date, these contributions have been voluntary and opportunistic but will evolve to a more formal pledging model similar to that of the LHC experiments.


\section{Data Types and Volumes}

Offline computing for  \dword{dune} faces new and considerable challenges due to the large scale and more diverse physics goals of the experiment.  In particular, the advent of \dwords{lartpc} with exquisite resolution and sensitivity, combined with enormous physical volumes, creates challenges in acquiring and storing large data volumes and in analyzing and reducing them.  \fixme{This answers at least part of question in an above section. AH}
As a result, the DUNE data structure is considerably different from previous neutrino and present collider experiments. \fixme{the following needs some tightening up. Low rates but lots of data? But data volumes much smaller than collider... Need to make a point, and I'm not sure what it is. AH} Neutrino experiments, including DUNE, run at low rates--of order \SI{1}{Hz} even for near detectors. But DUNE, due to its large volume and number of channels, can generate enormous amounts of data from a single readout.
This leads to unique new challenges in data storage and reconstruction, even where the total data volumes and CPU needs are significantly smaller than those for large collider experiments.  

In addition, the computing landscape is changing rapidly, with the traditional HEP architecture of individual cores running single-threaded applications being superseded by applications efficiently utilizing multiple processors and perhaps demanding GPUs. At the same time, algorithms for \dword{lar} reconstruction are still in their infancy and developing rapidly.  As a result, we have reason to be optimistic about the future but we are not able to predict it accurately.  The \dword{pdsp} test at \dword{cern} in the fall of 2018 has provided a wealth of data that will inform the future evolution of  the \dword{dune} computing models.

In this section we describe the data volumes and types expected for normal running, calibration, and \dword{snb} readouts of the \dword{fd} and the potential for the \dword{nd}. 


\subsection{Single-phase Technology Data Estimates}

 
Each of the 150 \dword{spmod} \dwords{apa} (described in  Section~\ref{sec:exec-sp-apa}) has 2,560 readout channels, each of which % each.Each channel 
is sampled with 12 bit precision every \SI{500}{ns}. 
For modules of this size, drift times in the \dword{lar} are of order \SI{2.5}{ms} and raw data sizes before compression are of order \SI{6}{GB} per module per \SI{5.4}{ms} readout window.  With no triggering and no zero suppression or compression, the raw data volume for four modules would be of order \SI{145}{exaB/year}. Table~\ref{tab:exec-comp-bigpicture} summarizes the relevant parameters for the \dword{sp} technology.  In our data volume calculations we assume that lossless compression and partial rather than full readouts of regions of interest in the far detector modules will occur.  Zero-suppression at the level of single channels is not assumed. 


\begin{dunetable}[Useful quantities for computing \dshort{sp} estimates]{lrr}{tab:exec-comp-bigpicture}
{Useful quantities for computing estimates for \dword{sp} readout}%\rowtitlestyle
Quantity&Value&Explanation\\ 
\toprowrule
{\bf Far Detector Beam:}\\ \colhline
Single APA readout &41.5 MB& Uncompressed 5.4 ms\\ \colhline
APAs per module& 150&\\
Full module readout &6.22  GB& Uncompressed 5.4 ms\\ \colhline
Beam rep. rate&\beamreprate&Untriggered\\ \colhline
CPU time/APA&100-200 sec&from MC/ProtoDUNE\\ \colhline
Memory footprint/APA&2 GB&ProtoDUNE experience\\ \colhline
{\bf Supernova:}\\ \colhline
Single channel readout &270 MB& Uncompressed 90 s\\ \colhline
Four module readout& 600 TB& Uncompressed 100 s\\ \colhline
Trigger rate&1  per month&(assumption)\\
\end{dunetable}


\begin{dunefigure}[Expected physics-related activity
    rates in one FD module]{fig:daq-rates}{Expected physics-related activity
    rates in a single \nominalmodsize module. Figure~from \spchdaq{}. \label{sec:fd-daq:rates}
}
  \includegraphics[width=0.7\textwidth,clip,trim=6cm 6cm 10cm 2cm]{daq-event-type-rates-vs-energy.pdf}
\end{dunefigure}

\begin{dunetable}
[Expected DAQ yearly data rates]
{p{0.3\textwidth}p{0.1\textwidth}p{0.5\textwidth}}
{tab:daq-data-rates-sp}
{Summary of expected data rates for initial single-module running with \dword{sp} technology from Volume~\volnumbersp{}, \voltitlesp{}.  The rates assume no compression, and are given for a single \nominalmodsize module. $^39$Ar decay candidates are not kept permanently; they are temporarily stored for one to two months at a time. The same applies to fake \dword{snb} data. Improved readout algorithms will be developed and evaluated with the initial data and are expected to provide about an order of magnitude reduction in data while retaining efficiency.}
Source& Annual Data Volume & Assumptions \\ \toprowrule
Beam interactions & 27 TB & 10 MeV threshold in coincidence with beam
time, including cosmic coincidence; \SI{5.4}{\milli\second} readout \\ \colhline
$^{39}$Ar, cosmics and atmospheric neutrinos & 10 PB & \SI{5.4}{\milli\second} readout \\ \colhline
Radiological backgrounds & $<2$ PB & $<1$ per month fake rate for SNB
trigger\\\colhline
Cold electronics calibration & 200 TB & \\ \colhline
Radioactive source calibration & 100 TB & $<10$ Hz source rate; single
APA readout; \SI{5.4}{\milli\second} readout \\\colhline
Laser calibration & 200 TB & 10$^6$ total laser pulses; half the
TPC channels illuminated per pulse; lossy
compression (zero-suppression) on all channels\\\colhline
Random triggers & 60 TB & 45 per day\\
\end{dunetable}



\subsection{Dual-phase Technology Data Estimates}

%For dual-phase, electrons drift the full height of the cryostat, emerge from the liquid and are collected - after gas amplification, on a grid of instrumented pads at the top of the detector.  The WA105 3x1x1 m test of this technology ran successfully in the summer of 2017\cite{Murphy:20170516}. 


Each \dword{dpmod} will have 153,600 readout channels. Drift time in the liquid argon is \SI{7.5}{ms}. Given 20,000 samples in an \SI{8}{ms} readout, the uncompressed event size is \SI{4.2}{GB} (for one drift window).  Due to gas amplification, the \dword{s/n} ratio is quite high, allowing lossless compression to be applied at the front-end  with a compression factor of ten, bringing the event size/module to \SI{.42}{GB}. Recording the entire module drift window can be considered a pessimistic figure, \fixme{??} since events are normally contained in smaller detector regions. A  \dword{fd} module can be treated as 20 smaller  detectors, each with a similar number  of readout channels as  \dword{pddp} %the prototype currently being constructed 
at \dword{cern}, running in parallel, each one defining a sub-module region of interest  (\dword{roi}). For beam or cosmic events it is possible to record only the interesting \dword{roi}(s) with the compressed size of a single \dword{roi} being \SI{22}{MB}.

\subsection{Data Rates}
\subsubsection{Beam Coincident Rates}

Requiring  coincidence with the \dword{lbnf} beam will reduce the effective live-time from $\sim\,$\SI{1.2}{s}  to a \SI{5.4}{ms}  readout window (\SI{8}{ms} for \dword{dp}) coincident with the \SI{10}{\micro\second} beam spill, leading to an uncompressed data size for beam-coincident events of around \SI{24}{GB} for four \SI{17}{kt} \dwords{spmod} (and somewhat less for \dword{dp}), too high to record permanently at full rate.
Only a few thousand true beam interactions in the \dword{fd} modules are expected each year.  Compression and conservative triggering based on \dwords{pd} and ionization should reduce the data rate from beam interactions by several orders of magnitude without sacrificing efficiency.  Studies discussed in %the \dword{daq} section of this proposal 
\spchdaq{} 
indicate that high trigger efficiencies are achievable at an energy threshold of \SI{10}{MeV}, leading to event rates for beam-initiated  interactions of $\sim\,$6,400/year.
Table \ref{tab:daq-data-rates-sp}, adapted from \spchdaq{}, %the \dword{daq} section,
 summarizes the expected uncompressed rates from one \dword{spmod}. 

\subsubsection{Near Detector} 

The \dword{nd} configuration is not yet fully defined  but we do have substantial experience from \dword{t2k} and  \dword{microboone} at lower energies, and  \dword{minerva} at the  \dword{dune} beam energies on cosmic and beam interactions under similar conditions.  We can expect that a \dword{nd} will experience $\sim\,$1 beam interaction/m$^3$/beam pulse and non-negligible rates of cosmic rays. Initial estimates are that zero-suppressed data rates will be of order \SI{10}{MB/s} leading to yearly data volumes less than a PB.  

\subsubsection{Processes not in Synchronization with the Beam Spill} 

Processes not associated with the beam spill %These ah 
include \dword{snb} physics, atmospheric neutrinos, proton decay, neutron conversion, and solar neutrinos.  These processes are generally at lower energy, making triggering more difficult, and are  asynchronous, thus requiring an internal or external trigger.  In particular, \dword{snb} signals will consist of a large number of low-energy interactions spread throughout the \dword{fd} volume over a time period of 1-100 seconds. Buffering and storing 100 seconds of data would require around 20,000 readout windows, or around \SI{600}{TB} per four-module \dword{snb} readout.  At a rate of one fake \dword{snb} event/month, this is around \SI{7}{PB} of uncompressed data per year.  Reconstructing and analyzing these data will require substantial evolution in our software frameworks, which were developed to process small (\SIrange{1}{100}{MB}) events on single processors. This is a major thrust of \dword{dune}'s computing R\&D for the future. 

\subsubsection{
Calibration}

In addition to physics channels, continuous calibration of the detectors will be necessary.  It is likely that, for the \dword{fd} modules, calibration samples will  dominate the data volume. Cosmic-ray muons and atmospheric neutrino interactions will provide a substantial sample for energy and position calibration.  Dedicated runs with radioactive sources and laser calibration will also generate substantial and extremely valuable samples. Table \ref{tab:daq-data-rates-sp} includes estimates for the %single-phase far detector.   
\dword{spmod}. 
$^{39}$Ar decays at rates of $\sim\,$1/kg/sec provide a uniform illumination of the detector volume to monitor electron lifetimes. As discussed in the appendices to %the Physics volume
Volume~\volnumberphysics{}, \voltitlephysics{},  a single \SI{5}{ms} readout of the full detector would provide 50,000 decays for study.  A small number of such readouts per day would provide a global monitor of conditions at the 1\% level, but measurements sensitive on meter scales will require a factor of $10^4$ more data and can become a significant fraction of the calibration data stream. In summary, $^{39}$Ar cosmic ray and atmospheric neutrino signals collected for calibration make up the bulk of the uncompressed \dword{sp} data volume at $\sim\,$\SI{10}{PB/year} per \SI{17}{kt} module and will dominate the rates from the \dword{fd} modules.  


\subsubsection{Zero Suppression}

The data volumes discussed above are for un-zero-suppressed readout of the full \dword{fd}. A combination of local triggering, zero suppression, and  efficient lossless compression mechanisms can substantially reduce the final data volume. However previous experience in HEP indicates that signal processing must be done carefully and often happens well into data-taking when the data are well understood. 
\fixme{the "this but that" doesn't seem to follow. AH}
Experience from  \dword{microboone}, \dword{sbn} experiments, and the \dword{protodune} experiments will aid us in developing these algorithms, but it is likely that they will be applied later in the processing chain for \dword{sp}.  No zero-suppression is planned for \dword{dp}.

The constrained environment at \dword{surf} motivates a model where any further data reduction is done downstream, either on the surface or after delivery to computing facilities at \dword{fnal} or elsewhere. This could be analogous to the \dwords{hlt} used by \dword{lhc} experiments. \fixme{could be?} The %relative \fixme{relative?} 
optimization of data movement and processing location is an important consideration for the design of both the \dword{daq} and offline computing. %, but t AH
The remote location and resource limitations imposed by the underground detector motivate placement of large-scale computing resources offsite. 


\subsection{Simulation}
The bulk of data collected with the \dword{fd} is likely to be background, with real beam interaction events in the \dword{fd} numbering in the thousands per year, not millions. Thus, the size of simulation samples may be %less 
smaller than the unprocessed raw data considered above.  Lower-energy events are either very rare or can be simulated in sub-volumes of the whole detector.  As a result, while simulation will be important to the experiment, it should not dominate data volume as it does in many experiments.  

However, simulation inputs such as flux files, overlay samples, and shower libraries pose a special challenge because they must be distributed to simulation jobs carefully.   Proper simulation requires that these inputs be distributed in unbiased parcels.  This can be technically difficult to do efficiently in a widely distributed environment and will require thoughtful design. 

\subsection{Analysis}

Analysis formats have not yet been fully defined.  We anticipate that most analysis samples will be many times smaller than the raw data.  However, because they are idiosyncratic to particular analyses and even users,  producing and cataloguing them will require carefully designed tools and substantial oversight. 
We need a mix of official samples, produced by physics groups and distributed through a common catalog and file transfer mechanisms, as well as small user samples on local disks. 

Final oscillation parameter scans with a large number of %nuisance 
parameters can be quite CPU-intensive.  For example, the \dword{nova} collaboration's recent physics results required tens of millions of  HPC CPU hours at the NERSC facility at \dword{lbnl}. DUNE collaborators used simpler models but the same techniques to generate some of the results presented in Volume~\volnumberphysics{}, \voltitlephysics{}. These large-scale analysis projects will require collaboration-wide coordination of resources and will benefit greatly from optimization for specific architectures.

\subsection{Data Storage and Retention Policies}
Some of the samples listed above are extremely valuable and will require conservative retention policies.   Examples include real neutrino and cosmic ray interactions in the far detector, most of the near detector data, and any real \dword{snb} events.  These data streams may require multiple copies be retained. Calibration samples and, potentially, fake \dword{snb} triggers may be stored temporarily and discarded after processing. 


\subsection{Summary}
In summary, uncompressed data volumes will be dominated by calibration for the \dword{fd} modules (10-15~PB/year/module) and by beam and cosmic ray interactions in the near detector.  With a  factor of four for lossless compression, a total compressed data volume of 3-5PB/year/module for four modules of the \dword{fd} is anticipated. Near detector rates are not yet established, but are likely to be smaller.   
%After discussion with the \dword{sp} Trigger/\dword{daq} group, we have 
The \dword{csc},  \dword{sp} \dword{daq}  and host laboratory %they 
have agree to specify  a  maximum data transfer rate from the \dword{fd} to \dword{fnal} of \surffnalbw, which is consistent with projected network bandwidths in the mid 2020's, and a limit of \SI{30}{PB/year} raw data stored to tape. 
%Table \ref{daq:datarates} summarizes the data rates expected from the \dword{daq} section of this proposal. 


\section{ProtoDUNE-SP as an Example}
\label{ch:exec-comp-proto-SP}
The first \dword{protodune} \dword{sp} run at \dword{cern} in late 2018 has already led to a %small-scale 
substantial test of the global computing model.  In the following, we will describe the \dword{protodune} data design and the lessons learned from our experience. Much of this carries over into planning for full \dword{fd} operations. 

\subsection{Introduction}


\dword{pdsp} ran at \dword{cern} in the \dword{np04} beamline from September to November of 2018. Since then, studies of cosmic rays have continued. Before that run, several data challenges at high rate validated the data transfer mechanisms. 

\subsection{Data Challenges}

\dword{protodune} performed a series of data challenges, starting in late 2017.  Simulated data were passed through the full chain from the event builder machines to tape storage at \dword{cern} and \dword{fermilab} at rates up to \SI{2}{GB/s}.  These studies allowed optimizing the network and storage elements well before the start of data taking.
Note that the full \dword{dune} \dword{fd} would, in writing \SI{30}{PB/s}, produce data at rates similar to  those demonstrated in the 2018 data challenges. While data rates are likely not technically challenging, the integrated data volume from an experiment that is up 99\% of the time over several decades will be. 

\subsection{Commissioning and Physics Operations}

The first phase of operations was commissioning the detector readout systems while the \dword{lar} reached full purity.  Data were taken with cosmic rays and beam during the commissioning period. Once high \dword{lar} purity had been achieved, physics data were  taken with beam through October and half of November. %Normal trigger rates were approximately 25 Hz, but tests were done at rates up to 100 Hz. 
Since the beam run ended, cosmic ray data continues to be taken with varying detector conditions, such as modified high voltage and purity, and new readout schemes. 


\subsection{Data Volumes}
\dword{pdsp} comprises a \dword{tpc} with  six \dword{apa}s, \dword{pd}s, and a \dword{crt}. In addition, the \dword{np04} beamline is instrumented with hodoscopes and Cerenkov counters to generate beam triggers. Random triggers  were generated at lower rates to collect unbiased cosmic ray information. The data volume from the test beam run was dominated by readout of the \dword{tpc}. % Each \dword{apa} has 2,560 channels and reads out 12 bit \dword{adc} values at 2 MHz. 
The nominal readout window during beam running was  \SI{3}{ms} to match the drift time at the full voltage of \SI{180}{kV}, which was maintained for most of the run.  The size of the \dword{tpc} data without compression was  \SI{138}{MB/event}, not including headers.  The uncompressed event size including all \dword{tpc} information and \dword{crt} and \dword{pd} data was \SIrange{170}{180}{MB}. Compression was implemented just before the October beam physics run, reducing the total size per event from around \SI{180}{MB} to \SI{75}{MB}.  In total, 8.1 million beam events were written with a total size of \SI{5205}{TB}.  An additional PB of commissioning data and cosmic ray data has also been recorded. 

\begin{comment}{Table \ref{
tab:exec-comp-pd-volumes} summarizes the raw data volumes.

\begin{dunetable}[Data volumes]{lrr}{tab:exec-comp-pd-volumes}{Data volumes  recorded by \dword{pdsp} as of December 2018.}
Type  & Events & Size\\ \rowtitlestyle
Raw Beam&8.08 M& 520 TB \\ \colhline
Raw Cosmics&3.46 M& 271 TB\\ \colhline
Commissioning&3.86 M& 388 TB\\ \colhline
Pre-commissioning&13.89 M&641 TB\\
\end{dunetable}
\end{comment}

Events were written out in \SI{8}{GB} raw data files with each containing approximately 100 events. The beam was live for two 4.5 s spills every 32 s beam cycle, and data were taken at  rates up to 50 Hz (typically 25 Hz), leading to compressed \dword{dc} rates of \SIrange{400}{800}{MB/s} from the detector.  

\begin{comment}\ignore{
\subsection{ProtoDUNE-SP Data Streams}
The \dword{pdsp} data consist of multiple sources in addition to the \dword{tpc} data. One of the major challenges for offline computing systems is merging these data streams into a coherent whole for analysis.  Table \ref{tab:exec-comp-pd-sources} lists the data sources used and their granularity. 

\begin{dunetable}[Data sources]{lrr}{tab:exec-comp-pd-sources}{Data sources.  }
Type & indexed by & destination\\ \colhline
TPC  & run/event & event data\\ \colhline
Photon Detector data & run/event & event data\\ \colhline
Cosmic Ray Tagger & run/event & event data\\ \colhline
Beamline devices & timestamp & beam database\\ \colhline
Detector conditions & timestamp & slow controls database\\ \colhline
DAQ configuration & run & files/elisa logbook\\ \colhline
Run quality & run & human generated spreadsheets\\ \colhline
Data quality & run/event/time & Data Quality web application\\ \colhline
File metadata & file & sequential access via metadata file database\\
\end{dunetable}
}\end{comment}


\subsection{Reconstruction of ProtoDUNE-SP Data}
Thanks to substantial previous effort by the \dword{35t}, \dword{microboone}, and the \dword{lar} \dword{tpc} community, high quality algorithms were already in place to reconstruct the \dword{tpc}  data.  As a result, a first pass reconstruction of the \dword{pdsp} data with beam triggers was completed by early December, less than a month after data taking ended.  Results from that reconstruction are presented in \physchtools %the Methods section of Volume~\volnumberphysics, \voltitlephysics{} 
with some highlights summarized here. 



\subsection{Data Preparation}

Before pattern recognition, data from the \dword{protodune} detector is
unpacked and copied to a standard format within the \dword{art} framework based on \dword{root} objects. 
This reformatted raw data includes the waveform for each channel, consisting of 6,000-15,000,  12-bit, 0.5 $\mu$sec samples. 
The first step in reconstruction is data preparation to
convert each \dword{adc} waveform into a calibrated charge waveform with
signals proportional to charge. At the end of data preparation, hit-level \dword{roi}s are identified, and the data outside these regions are discarded.  This leads to significant reduction in data size. This process is described more fully in~\cite{bib:docdb12349}. % and in the Methods section of the Volume~\volnumberphysics, \voltitlephysics{}.% but is summarized here: \fixme{get methods sec ref}
\begin{comment}\ignore{
\begin{enumerate}
\item Each waveform is unpacked into integers.
\item Pedestals are determined per event/per channel from the most common \dword{adc} value. 
\item Pedestals and calibrations are applied. %\label{local:ped}
\item Bad channels, sticky bits, and other known hardware problems are corrected or removed.
\item Signal undershoot that creates a long negative tail is removed. 
\item The waveforms  are deconvoluted.  In the first processing, this was done with simple 1D  convolution for a single wire.  A \twod  method of deconvoluting a detailed detector electrostatic field map, originally developed for \dword{microboone}\cite{Adams:2018dra}, is  now available for \dword{protodune} and will be used in the future reconstruction passes.  It properly undoes the long-range induction effects while keeping efficiency high and bias low.  The deconvolution Fourier transforms the waveform, replaces the  bipolar field response function with a unipolar function, applies a low-pass filter to remove high-frequency noise, and then transforms back.

\fixme{One dimensional (1d) and two dimensional (\twod) should be consistent with one another and probably in LATEX code. (Anne says: I just use \twod and \threed from defs for consistency.)}




\item Finally, regions of interest are defined where the signal exceeds a given threshold, and time slices well outside the \dshort{roi} are dropped. These data feed into the reconstruction algorithms for further pattern recognition. %\label{local:roi}
\end{enumerate}
}\end{comment}


Figures~\ref{fig:ch-exec-comp-chtraw} and~\ref{fig:ch-exec-comp-chtroi} illustrate the transformation of \dword{tpc} data  during data preparation. Note that this represents one wire plane for 3 ms.  A full 5.4 ms readout of a single \nominalmodsize module would contain a factor of 750  more information than this image.

\begin{figure}[t]
\includegraphics[width=\textwidth,angle=0]{comp-evd_twq-proj_5449_20926_raw.png}
\caption[Example of pedestal-subtracted data for one of the ProtoDUNE-SP  wire planes]{Example of pedestal-subtracted data for one of the ProtoDUNE-SP  wire planes.  The top pane shows the ADC values in a V (induction) plane with the x-axis being channel number and the y-axis, time slice. The bottom pane shows the bipolar pulses induced on one channel. 
}
\label{fig:ch-exec-comp-chtraw}
\end{figure}


\begin{figure}[t]
 \includegraphics[width=\textwidth]{comp-evd_twq-proj_5449_20926_decon.png}
\caption[Pedestal-subtracted data for one of the ProtoDUNE-SP  wire planes, additional processing]{
Pedestal-subtracted data for one of the ProtoDUNE-SP  wire planes, as Figure~\ref{fig:ch-exec-comp-chtraw}, but shown after calibration, cleanup, deconvolution and \dword{roi} finding. 
}
\label{fig:ch-exec-comp-chtroi}
\end{figure}


\subsection{Computational Characteristics of Data Preparation and Deconvolution }

Decoding for \dword{pdsp} was originally done with all six \dword{apa}s in memory. Each \SI{3}{ms} of \dword{apa} readout consists of more than \SI{15}{M} 16-bit values. Decompressing and converting this information to floating point format causes substantial memory expansion. 
  Data with a 7.5 ms window were also taken. 
The input and output event sizes and reconstruction time scale were found to scale linearly with the readout window and with the number of \dword{apa}s processed. 


Because electrical signals are correlated between channels within an \dword{apa} wire plane but not between planes, processing each wire plane (three per \dword{apa}) independently reduces the memory footprint.
However,  while subdividing the detector into wire planes reduces the memory footprint for short (beam-related) readouts, it is  not a viable solution for the long readouts expected for \dword{snb} events. We are still exploring the best strategy for dealing with these much larger ($\times 10,000$) time windows. 
The \dword{daq} consortium is exploring methods for segmenting large events (such as \dwords{snb}) into  smaller of \dword{roi}s in both time and space for efficient readout.  As long as those regions are on the scale of single interactions, the resulting data should fit in a reasonable memory budget at the expense of tracking and collating many distributed interactions. 

The operations performed in signal processing require few decisions, but do include operations such as fast Fourier transforms and deconvolution.  These operations are well suited for GPU and parallel processing. We are actively exploring multi-threaded processing for all data preparation algorithms. 


\subsection{Reconstruction Characteristics}



Once \dword{roi}s have been identified, several \threed  reconstruction packages are used. For the first reconstruction pass in November, the  \dword{pandora}~\cite{Acciarri:2017hat}, \dword{wirecell}~\cite{wirecell}, and \dword{pma}~\cite{ref:PMA}  frameworks were used with results described in Volume~\volnumberphysics{}, \voltitlephysics{}. 
Figure~\ref{fig:ch-exec-comp-tracking}  is taken from the from Volume~\volnumberphysics{} and illustrates the measured efficiency for the Pandora algorithm reconstructing a triggered beam particle as a function of momentum for the simulation and data for selected data taking runs. As can be seen, the efficiency is already quite high and reasonably well simulated.




Full reconstruction of these \dword{pdsp} interactions, with beam particles and approximately 60 cosmic rays per readout window, took of order 600 sec/event with around 200 sec in the signal processing and hit finding stages, and the remaining time divided between three different pattern recognition algorithms. Output event records were substantially smaller (22 MB compressed) and still dominated by the information for \dword{tpc} hits above threshold. 

All of these algorithms are currently being run on conventional UNIX CPUs using \dword{osg}/\dword{wlcg} grid computing  infrastructure. Deep learning techniques based on image pattern recognition algorithms are also being developed. Many of these algorithms can be adapted to run on \dwords{hpc} assets, although the optimal architecture for \threed reconstruction likely differs from the optimum for hit finding.


\begin{figure}[htp]
\centering
\includegraphics[height=4in]{graphics/BeamParticleEfficiencyVsMomentum.pdf}
\caption[Efficiency of reconstruction for the triggered test beam particle]{The efficiency of reconstruction for the triggered test beam particle as a function of particle
momentum in data (red) and simulation (black). Figure~5.27 from Volume~\volnumberphysics{}, \voltitlephysics{}.}
\label{fig:ch-exec-comp-tracking}
\end{figure}






\begin{comment}\ignore{
\begin{dunetable}
[Data storage  and CPU needs for reconstruction of ProtoDUNE test beam data]
{llrrrr}{tab:exec-comp-needs}{Data storage and CPU needs for reconstruction of ProtoDUNE-SP test beam data taken in 2018 and projections for 2019-2021.  We assume two copies of raw data are stored and that each event is reconstructed twice.  Analysis and simulation are estimated to be of order the same CPU use as reconstruction based on the 2018 experience.}%\rowtitlestyle
Detector& value &
2018&
2019&
2020&
2021\\\colhline
&&As built\\\colhline
SP&
Events, M&
15.1&
13.0&
6.5&
40.5\\\colhline
&
Raw data, TB&
1047&
2239&
1120&
2799\\\colhline
&
Reco data, TB&
2094&
4479&
2239&
5599\\\colhline
&
CPU, MH&
5.0&
4.3&
2.2&
13.5\\\colhline
DP&
Events, M&
0.0&
101.1&
56.2&
119.9\\\colhline
&
Raw data, TB&
0&
809&
449&
1799\\\colhline
&
Reco data, TB&
0&
1617&
899&
3598\\\colhline
&
CPU, MH&
0.0&
33.7&
18.7&
40.0\\\colhline
total&
Events, M&
15.1&
114.0&
62.6&
160.4\\\colhline
&2x
Raw data, TB&
2094&
6096&
3138&
9197\\\colhline
&
Reco data, TB&
2094&
6096&
3138&
9197\\\colhline
total&Storage, TB&
4188&
12193&
6276&
18394\\\colhline
&
Reco CPU, MH&
5.0&
38.0&
20.9&
53.5\\\colhline
&
Analysis CPU, MH&
5.0&
40.0&
40.0&
40.0\\\colhline
Total&CPU, MH&
10.0&
78.0&
60.9&
93.5\\
\end{dunetable}
}\end{comment}



\subsection{Lessons Learned}
The first \dword{pdsp} run has given us very valuable information for planning the full \dword{dune} computing model. 

\begin{itemize}
    \item Data and simulation challenges led to a reasonably mature and robust model for acquiring, storing, and cataloging the main data stream at design rates.
    \item The experiment integrated several existing grid sites and used substantial opportunistic resources.  This allowed initial processing of data within one month of the end of the run.
    \item Prototype infrastructure was in place for provisioning, authentication and authorization, data management, networking, file catalog, and workflow management. 
    \item Reconstruction algorithms were available and allowed immediate studies of detector performance and calibration. 
    \item Beam information was successfully integrated into processing through the \dword{ifbeam} database.
    \item Auxiliary information from, for example, slow controls, was not fully integrated into processing which led to  manual input of running conditions by shift personnel and offline incorporation of that information into the data catalog. This has led to closer collaboration with the \dword{daq} and \dword{cisc} groups in designing robust interfaces for configurations and conditions. 
\end{itemize}

Overall, the \dword{pdsp} data taking and processing was a success, despite being overly dependent on doing things manually because automated processes were not always in place. Considerable effort must go into integrating detector conditions, data migration, workflow systems, and \dword{hpc}s with multi-threaded and vectorized software.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{comment}\ignore{
\section{Data Model for the Far and Near Detectors}
\label{ch:exec-comp-mod}

%%%%%%%%%%%%%%%%%%%%
%\subsection{Introduction}
%\label{ch:exec-comp-mod-int}
In parallel with the \dword{pdsp} data, a joint data model task force was formed by the \dword{daq} and \dword{csc} to build a framework for the full \dword{dune} \dword{nd} and \dword{fd}. 
The data model task force grappled with the problems of efficiently triggering, reading out, and storing data on multiple time scales from an enormous detector.

They defined major concepts.


\begin{itemize}

\item{Configuration:} Set of parameters that define the persistent, expected detector state. Globally, this corresponds to a desirable state for the detector, capable of providing data of physics or calibration quality. Each component of the detector may have its own configuration.
 
\item{Run:} Period over which data has been collected across some set of desired components in a consistent configuration.
 
\item{Sub-run:} Period within a run over which data has been collected across some set of desired components in a consistent configuration. The set of desired components in a sub-run must be a subset of the desired components for a run and is the set of components over which data is expected.
 
(Time-based rollovers of runs and sub-runs may be automatic. Differences between sub-run and run due to configuration or changes in the desired components will be tracked by the \dword{daq} and may be either manual or automatic.)
 
\item{Trigger:} Data from the desired components in a sub-run over a readout window. This would typically be centered around a trigger time and is what is recorded by the \dword{daq}. The readout window may be subdivided into frames as determined by the \dword{daq}.
 
\item{Event:} Subset of a trigger isolated in time and space containing an independent interaction in the detector. Events may overlap in space or time within the same trigger. This is generally determined by the offline reconstruction of data in a frame.

\end{itemize}

These definitions are intended to allow triggering, recording, and reconstruction of interactions in subsets of the detector. While the whole detector (or time window) can produce enormous amounts of data, any individual interaction should span a reasonably short time and spatial volume. A data model that can isolate individual interactions  allows interactions to be efficiently stored and reconstructed. 


The main data stream will be augmented by beam, slow controls, \dword{daq} configuration, and calibration information. 

This work continues and informs  the  joint  calibration, \dword{csc} and \dword{daq} designs.

}\end{comment}


\section{Conclusion}

The \dword{dune} \dword{csc} has already undergone a substantial test with the successful run of \dword{pdsp}, including demonstrating data movement to storage at \SI{2}{GB/s}, reconstructing the full test beam sample with high-quality algorithms, and beginning analysis of the multiple PB reconstructed data. 

The \dword{csc} is now working with the global HEP computing community to evaluate and specify modern infrastructure that will serve the needs of \dword{dune} and the rest of the community.  We plan to collaborate wherever possible with other experiments where we have common technical challenges. However, the extremely large but simple events generated by \dword{lar} \dwords{tpc}, even with short readouts, present a unique challenge. 

Over the next two years our major activities  will be  thoroughly reviewing available and potential tools, continuing collaborations, and acquiring the resources, most importantly personnel,  necessary to launch this large suite of ambitious projects. 

=======

\newcommand{\ignore}[1]


\chapter{Computing in DUNE}
\label{ch:exec-comp}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Executive Summary}
\label{ch:exec-comp-es}

%The \dword{dune}  collaboration comprises 178 institutions from 32 countries, including 15 European nations and the \dword{cern}. AH
The \dword{dune} experiment is preparing to commission the first \nominalmodsize fiducial mass \dword{lartpc} module between 2024 and 2026 with a long data-taking run, the number of module will increase to four between 2026 and 2036 and beyond.  An active prototyping program is already in place and has had  a short test beam run in 2018 at \dword{cern}.  These tests used  a \SI{700}{t}, 15,360 channel prototype \dword{tpc} with \dword{sp} readout.  Tests of a \dword{dp} detector of similar size are scheduled for mid-2019.   The \dword{dune} experiment has already  benefited greatly from these initial tests.  The collaboration has recently formed a formal \dword{csc}, with significant participation by European institutions and interest from groups in Asia, to develop common software and computing and to formalize resource contributions.

The consortium resource model benefits from existing \dword{osg}  and \dword{wlcg} infrastructure developed for the \dword{lhc} and broader \dword{hep} community.  \dword{dune} %, through  \dword{pdsp}, AH 
is already using global resources for simulating and analyzing  \dword{pdsp} data.  Several European institutions are part of this resource pool and are making significant contributions to the \dword{pdsp} and \dword{pddp} programs.  We expect this global computing consortium to grow and evolve as we move towards gathering data from the full \dword{dune} detector in the 2020s.

The long-term \dword{dune} science program should produce raw data volumes similar in scale to the data volumes that current \dword{lhc} Run-2 experiments have already handled successfully.  Baseline predictions for the \dword{dune} data, depending on actual detector performance and noise levels, are $\sim\,$\SI{30}{PB} of raw data per year.  These data, with simulations and derived analysis samples, must be available to all collaborating institutions.  We anticipate that institutions worldwide will be both contributors and end-users of storage and CPU resources for \dword{dune}.




\dword{dune} starts with considerable infrastructure in place for international computing collaboration thanks to the \dword{lhc} program.  Additional large non-\dword{lhc} experiments, 
such as \dword{lsst}, the \dword{belleii} B-factory experiment, and \dword{dune}  will enter operation over the next decade and must use and expand upon this model for international cooperation.  Organizing the broader HEP community is formalized through the \dword{hsf}~\cite{Alves:2017she}.  The \dword{hsf} is an organization of interested parties working to use the extensive knowledge gained over the past two decades to %  and ah
anticipate the needs of experiments %will have ah 
over the next two decades to develop a sustainable computing landscape for the HEP community.  The \dword{hsf} white papers and roadmaps emphasize common tools and infrastructure as the underpinnings of this landscape.

\dword{dune}'s computing strategy heavily leverages this model of common tools and infrastructure and features data movement and storage, job control and monitoring, accounting, and authentication that both use and contribute to this global community.   \dword{dune} recognizes that other large-scale experiments have similar needs and will encounter similar issues, thus driving worldwide cooperation on common tools as the most cost-effective way to fulfill the scientific missions of the experiments.  \dword{dune} pilot programs already use this model.  Most recently in data management and storage, \dword{fermilab}, \dword{cern}, Rutherford Appleton Laboratory, and other academic institutions in the %United Kingdom ah
UK are collaborating on adapting and using the \dword{rucio} data management systems~\cite{Barisits:2019fyl}  to serve as the core data management system for \dword{dune}.

%Examples of 
This protoculture of international collaboration within \dword{dune} %were 
was demonstrated during the 2018 test beam run of the \dword{pdsp} detector  at \dword{cern}.  During this run, % the \dword{sp} ah
\dword{pdsp} produced raw data at rates of up to \SI{2}{GB/s}.  These data were transferred and stored in the archive facilities at \dword{cern} and \dword{fermilab}, and replicated at sites in the UK and Czech Republic.  In a more recent commissioning test for the \dword{pddp} detector, similar rates %have been 
were achieved to \dword{cern}, \dword{fermilab} and the CCIN2P3 computer center in Lyon, France.

In total, \SI{1.8}{PB} of raw data were produced during the ten week test beam run, mimicking, within a factor of two, expected data rates and volumes from the initial running of the \dword{fd} complex.  The prototype run was used to examine and test the scalability of existing and proposed computing infrastructure and to establish operational experience within the institutions that have expressed interest in the development and construction of the \dword{dune} computing environment.  Our planning is based heavily on the measurements and information gained from the \dword{protodune} experience.   These measurements are proofs-of-concept for many of the systems, and their behavior can be extrapolated to the projected levels needed for the full \dword{dune} experiment. 



In summary, \dword{dune}'s computing strategy must be global--working with partners worldwide--and collaborative because almost all computational challenges we face are also %those facing ah
faced by similar experiments.  We are extremely fortunate to have the ProtoDUNE test data to exercise our computing infrastructure and to develop algorithms for  full \dword{dune} operations.
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Computing Consortium}
\subsection{Overview}
\label{ch:exec-comp-ovr}

The mission of the \dword{dune} %computing consortium (CSC) ah
\dword{csc} is to facilitate the acquisition, processing, and analysis of both detector data and supporting simulations for the %\dword{dune} ah
experiment.  This mission must extend over all of the primary physics drivers for the experiment and must do so both cost effectively and securely. The \dword{csc} provides the bridge between  online \dword{daq} and monitoring systems and the different physics groups who develop high-level algorithms and analysis techniques to perform measurements with the \dword{dune} data and simulations. The \dword{csc} works with collaborating institutions to identify and provide computational and storage resources.  %They provide ah
It provides the software and computing infrastructure in the form of analysis frameworks, data catalogs, data transport systems, database infrastructure, code distribution mechanisms, and other support services essential for recording and analyzing the data and simulations. 

The \dword{csc} works with national agencies and major laboratories to negotiate use and allocation of computing resources.  This work includes support for near-term and R\&D efforts %like ah 
such as \dword{protodune} runs, and extends to the design, development, and deployment of the \dword{dune} computing model and its requisite systems. 
These designs include evaluating major software infrastructure systems to determine their usefulness %for 
in meeting the \dword{dune} physics requirements.   These evaluations should identify opportunities to adopt or adapt existing technologies and to engage in collaborative ventures with HEP experiments outside of \dword{dune}. 

\fixme{this needs a different heading. AH}

At first glance,  the \dword{dune} CPU and storage needs %are ah
appear modest %on the scale of ah
relative to the projected rates and needs for the high-luminosity \dword{lhc} experiments.  
However, the  beam structure, event sizes, and analysis methodologies make \dword{dune} very unlike collider experiments %in ah
as regards event processing needs and projected computational budgets. \fixme{What are the features of these items that are different? AH} The large \dword{dune} event sizes present a novel technical challenge when data processing and analysis are mapped onto  current and planned computing facilities. \fixme{previous sentence needs clarification once we understand the novel aspects. AH} %In particular, the advent of high-performance computing systems optimized for parallel processing of large data arrays presents \dword{dune} with a potential advantage, as our event structure is more suited to those architectures than conventional tracker-based HEP data. AH
The advent of high-performance computing systems optimized for parallel processing of large data arrays is a great advantage for \dword{dune}. These architectures suit \dword{dune}'s event structure quite well, more closely than they do conventional tracker-based HEP data. \fixme{we need the background to understand why. AH}

Neutrino oscillation analysis and parameter extraction also present %novel computational 
challenges.  \fixme{what's novel about them? AH}

%These novel features of \dword{dune} data ah
\dword{dune} will require significant effort to adapt to the emerging  %available 
global computing resources that % available to the experiment.ah 
%These global resources ah
will  likely be both more heterogeneous in computational capabilities (e.g., featuring CPU, GPU, and other advanced technologies) and more diverse in topological architectures and provisioning models.  The \dword{dune} \dword{csc} must %address these issues of diversity and architecture ah
be ready to fully exploit these global resources %available ah 
after 2026 and enable all collaborators to access the data and perform the scientific mission of the experiment.  



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Resources and Governance}
\label{ch:exec-comp-gov}

%The computing and software group is now a \dword{dune} consortium. ah
The \dword{csc} was formed from an earlier ad-hoc \dword{dune} computing and software group. % in \fixme{date?}
Reference~\cite{bib:docdb12751} describes the governance structure for the consortium.  The consortium coordinates effort across the collaboration, but funding comes from collaborating institutions, laboratories, and national funding agencies. Aside from a small fraction of the consortium leadership, it is not supported by \dword{dune} or \dword{lbnf} project funds.  \fixme{lbnf?}

The %consortium 
\dword{csc} has an overall consortium leader %. The consortium leader 
who is responsible for the subsystem deliverables and represents the consortium in the overall \dword{dune} collaboration.
In addition, technical leads act as overall project managers for the consortium. The technical leads report to the overall consortium leader.
\dword{csc} has both a host laboratory technical lead to coordinate between the \dword{dune} project and Fermilab, the host laboratory, and an external technical lead to coordinate with other entities.
At least one of the three leadership roles should be held by a non-US scientist. 
Other roles are currently filled on a voluntary basis by the consortium management.  A more formal structure for institutional contributions and commitments is being constructed. 


\begin{figure}[htp]
\centering
\includegraphics[height=3in]{graphics/comp_Org_Chart.pdf}
\caption[Organization chart for current \dshort{csc}]{Organization chart for current \dword{csc}. }
\label{fig:ch-exec-comp-org}
\end{figure}

\subsection{Scope of the Consortium}
The \dword{csc}'s focus is the hardware and software infrastructure  for offline computing.  Responsibility for development of algorithms  resides within the physics groups, %while ah
and online systems at experimental sites are governed by the \dword{daq} and \dword{cisc} consortia. The \dword{csc} plays a coordinating role through the definition of interfaces, coding standards, and training. All groups coordinate closely to ensure that the full chain of data acquisition, processing, and analysis %works
functions properly. Formal interfaces with the \dword{daq} and controls groups are described in~\cite{bib:docdb7123,bib:docdb7126}. % Docdb 7123 (DAQ)\cite{bib:docdb7123} and Docdb 7126 (CISC)\cite{bib:docdb7126}.

The \dword{csc} operates at two levels: at the hardware level, where generic resources can be provided as in-kind contributions to the collaboration, and at the human level, where individuals and groups help develop common software infrastructure.  The   technology for hardware contributions (grid CPU and storage) exists and was exercised during the \dword{pdsp} data run and its associated %"associated" added by ah
simulation and reconstruction. Highlights of that effort are discussed below and in \physchtools{}. % the Tools and Methods section of the Physics volume.  



\begin{figure}[htp]
\centering
\includegraphics[height=3in]{graphics/comp-ComputingLastYear.png}
\caption[CPU wall-time from July 2018 to July 2019]{CPU wall-time from July 2018 to July 2019, the 1st peak shows  ProtoDUNE-SP reconstruction while the second is dominated by data analysis and ProtoDUNE-DP simulation. A total of 31 million wall-hours were delivered with 24 M-hrs coming from Fermilab.  }
\label{fig:ch-exec-comp-cpupie}
\end{figure}


\subsection{Hardware Infrastructure}
As illustrated in Figure~\ref{fig:ch-exec-comp-cpupie}, the \dword{dune} collaboration has already used substantial global resources through the \dword{wlcg} and \dword{osg} mechanisms. As the experiment evolves over the next five years, institutions and collaborating nations will be asked to formally pledge resources (both CPU and storage), and those resources will be accounted for and considered in-kind contributions to the collaboration.  A   computing resources board  is being set up to administer this process and liaise with national resource providers. 

Several international partners are already contributing substantially to CPU resources, and we continue to  integrate additional large national facilities. Most CPU resources are opportunistic, but \dword{fermilab} and \dword{cern} have committed several thousand cores and several PB of disk. Additionally,  \dword{dune} has been one of the first beneficiaries of the UK's IRIS project to provide computing for astronomy and particle physics.  
We are working with \dword{osg} and \dword{wlcg} to integrate reporting mechanisms for CPU utilization so that accurate monitoring of hardware contributions will be in place for the second \dword{protodune} run in 2021-2022 and the buildup to data taking in the mid 2020's. 


\begin{dunetable}
[DUNE CSC institutions as of July 2019]{lll}{tab:exec-comp-consortium}{DUNE Computing and Software Consortium members as of July 2019.}%-- indicates sites not yet integrated into production computing. }%\rowtitlestyle
Institution& Country \\\colhline%& Integrated\\
KISTI&Korea\\\colhline %&--\\
TIFR  & India \\\colhline%& in process \\
Nikhef&NL\\\colhline%&Yes\\
Edinburgh&UK\\\colhline%&Yes\\
Manchester&UK\\\colhline%&Yes\\
RAL/STFC&UK\\\colhline%&Yes\\
CIEMAT/PIC&ES\\ \colhline
Argonne&USA\\\colhline%&Yes\\
BNL&USA\\\colhline%&Yes\\
Cincinnati&USA\\\colhline%& Yes\\
Colorado State&USA\\\colhline%& Yes\\
CU Boulder&USA\\\colhline%&Yes\\
Fermilab&USA\\\colhline%& Yes \\
Florida &USA\\\colhline%& Yes\\
LBNL&USA\\\colhline%&Yes\\
Minnesota&USA\\\colhline%&Yes\\
Northern Illinois Univ.&USA\\\colhline%&USA& --\\
Notre Dame&USA\\\colhline%&Yes\\
Oregon State University&USA\\\colhline%&Yes\\
Tennessee&USA\\\colhline%&--\\
Texas, Austin&USA\\%&--\\
\end{dunetable}

\subsection{Personnel}


Development of a  dedicated \dword{dune} computing team, responsible for operations and development of new tools specific to DUNE's needs is ongoing. 
Figure~\ref{fig:ch-exec-comp-org} shows the current organization.  Very few of these individuals are full time on DUNE, and we largely rely on use of common tools and techniques shared with other, smaller, experiments at \dword{cern} and \dword{fnal}. In particular, DUNE currently operates as one of several ``intensity frontier'' experiments at \dword{fnal}, with access to substantial shared resources but very few personnel assigned specifically to DUNE.  As one of our basic design tenets is cooperation and reuse of tools with the broader community, a significant shared component is indeed useful, but a small team of dedicated personnel still needs to be built. 
The full DUNE software and computing effort will be much larger in scale and needs to begin serious construction and operations well before commissioning begins at \dword{surf}. The unique DUNE data footprint and anticipated evolution in processor technologies will necessitate major efforts to construct and operate the computing infrastructure that we will need for the full experiment.

Personnel resources similar in scale to that for \dword{lhcb} and \dword{belleii}, which have a similar collaboration size and international scope, will be needed.  \fixme{how many people do they have?}
Much of the high-level algorithm development will be done by collaboration scientists, but a dedicated core group of experts with strong programming and project management skills will be needed to build and operate the core software infrastructure for the experiment.  We have used the \dword{lhcb} organization structure for a first estimate of our future personnel requirements.

Appendix \ref{comp-roles} describes  computing personnel activities in detail.  In summary, around ten \dword{fte} of software development will be needed to develop and maintain the core software necessary to run \dword{dune} algorithms and the distributed software infrastructure.  Some of this effort will be shared with other collaborations and \dword{hsf}/\dword{wlcg} projects, but in return, DUNE will need to make substantive contributions to those common efforts. In addition, %there are 
specific operational roles such as data manager, code librarian, user support, and management %that 
will require personnel dedicated specifically to DUNE computing. Based on \dword{lhcb} experience, we have identified ten such roles 
requiring full-time-equivalent \dword{fte} of 0.5 to 2.0.  These roles can be filled by experienced DUNE collaborators or computing professionals and their contributions to the experiment should be  recognized. 



The \dword{csc} is instituting a series of workshops, starting with one called ``Data Model and Infrastructure'' in the summer and fall of 2019, to set the scope of the subprojects in preparation for a formal computing \dword{tdr}. Table~\ref{tab:comp-milestones} gives a draft timeline for the computing project.

\begin{dunetable}[Milestones for DUNE computing development]{l l r}{tab:comp-milestones}{Milestones for DUNE computing development.  Data volumes assume 15 PB/year of compressed raw data starting in 2024.}
Year	&	Activity	&	integrated data, PB	\\ \toprowrule%
2018	&  	&	10	\\ \colhline
	& 	\dshort{pdsp} beam run	&	\\ \colhline
2019	&		&	19	\\ \colhline%
	&	\dshort{pdsp} processing	&		\\ \colhline%
	&	\dshort{pddp} commissioning and data taking	&		\\ \colhline%
	&	Develop resource model	&		\\ \colhline%
	&	Develop high level task list	&		\\ \colhline%
2020	&		&	21	\\ \colhline%
	&	Continue \dshort{protodune} processing/operations	&		\\%
	&	Formalize international resource model	&		\\ \colhline%
	&	Build operations team	&		\\ \colhline%
	&	Evaluate data and computing models	&		\\ \colhline%
	&	Data base design for hardware	&		\\ \colhline%
2021	&		&	25	\\ \colhline%
	&	CDR/TDR	&		\\ \colhline%
	&	Produce Computing TDR	&		\\ \colhline%
	&	Framework modifications for HPC 	&	\\ \colhline%	
	&	Data base design for conditions/configuration	&		\\ \colhline%
2022	&		&	39	\\ \colhline%
	&	\dshort{protodune} second beam run	&		\\ \colhline%
	&	Begin large scale purchases for FD commissioning	&		\\ \colhline%
2023	&		&	43	\\ \colhline%
	&	Reconstruct/analyze \dshort{protodune} results	&		\\ \colhline%
	&	Continue \dshort{protodune} processing/operations	&		\\ \colhline%
	&	Support FD commissioning	&		\\ \colhline%
	&	Conditions and configuration data fully integrated	&		\\ \colhline%
	&	Acquire storage for first year of data from one module	&		\\ \colhline%
2024	&		&	66	\\ \colhline%
	&	First real data from one FD module	&		\\ \colhline%
	&	Full operations team in place	&		\\ \colhline%
	&	Data analysis challenges	&		\\ \colhline%
2025	&		&	88	\\ \colhline%
	&	Complete provisioning of hardware/storage for first beam run	&		\\ \colhline%
2026	&		&	111	\\ \colhline%
	&	First beam run with two modules 	&	 	\\%
	\end{dunetable}
\todo{Need to confirm timeline}

\subsection{Resource Contributions}


A formal resource funding model is being developed through the \dword{csc} Resource Board. Present thinking is that collaborating countries will be expected to contribute to the computing physical resource and operational duties (e.g. shifts) on a fair-share basis that will be developed in consultation with the full DUNE collaboration.  Core software development effort is expected to come from \dword{csc} members.  Contributions will be a mix of CPU resources, storage and personnel with the mix tailored to the resources and capabilities of the county/institution. To date, these contributions have been voluntary and opportunistic but will evolve to a more formal pledging model similar to that of the LHC experiments.


\section{Data Types and Volumes}

Offline computing for  \dword{dune} faces new and considerable challenges due to the large scale and more diverse physics goals of the experiment.  In particular, the advent of \dwords{lartpc} with exquisite resolution and sensitivity, combined with enormous physical volumes, creates challenges in acquiring and storing large data volumes and in analyzing and reducing them.  \fixme{This answers at least part of question in an above section. AH}
As a result, the DUNE data structure is considerably different from previous neutrino and present collider experiments. \fixme{the following needs some tightening up. Low rates but lots of data? But data volumes much smaller than collider... Need to make a point, and I'm not sure what it is. AH} Neutrino experiments, including DUNE, run at low rates--of order \SI{1}{Hz} even for near detectors. But DUNE, due to its large volume and number of channels, can generate enormous amounts of data from a single readout.
This leads to unique new challenges in data storage and reconstruction, even where the total data volumes and CPU needs are significantly smaller than those for large collider experiments.  

In addition, the computing landscape is changing rapidly, with the traditional HEP architecture of individual cores running single-threaded applications being superseded by applications efficiently utilizing multiple processors and perhaps demanding GPUs. At the same time, algorithms for \dword{lar} reconstruction are still in their infancy and developing rapidly.  As a result, we have reason to be optimistic about the future but we are not able to predict it accurately.  The \dword{pdsp} test at \dword{cern} in the fall of 2018 has provided a wealth of data that will inform the future evolution of  the \dword{dune} computing models.

In this section we describe the data volumes and types expected for normal running, calibration, and \dword{snb} readouts of the \dword{fd} and the potential for the \dword{nd}. 


\subsection{Single-phase Technology Data Estimates}
 
Each of the 150 \dword{spmod} \dword{apa}s (described in  Section~\ref{sec:exec-sp-apa}) has 2,560 readout channels, each of which % each.Each channel 
is sampled with 12 bit precision every \SI{500}{ns}. 
For modules of this size, drift times in the \dword{lar} are of order \SI{2.5}{ms} and raw data sizes before compression are of order \SI{6}{GB} per module per \SI{5.4}{ms} readout window.  With no triggering and no zero suppression or compression, the raw data volume for four modules would be of order \SI{145}{exaB/year}. Table~\ref{tab:exec-comp-bigpicture} summarizes the relevant parameters for the \dword{sp} technology.


\begin{dunetable}[Useful quantities for computing \dshort{sp} estimates]{lrr}{tab:exec-comp-bigpicture}
{Useful quantities for computing estimates for \dword{sp} readout}%\rowtitlestyle
Quantity&Value&Explanation\\ 
\toprowrule
{\bf Far Detector Beam:}\\ \colhline
Single APA readout &41.5 MB& Uncompressed 5.4 ms\\ \colhline
APAs per module& 150&\\
Full module readout &6.22  GB& Uncompressed 5.4 ms\\ \colhline
Beam rep. rate&\beamreprate&Untriggered\\ \colhline
CPU time/APA&100-200 sec&from MC/ProtoDUNE\\ \colhline
Memory footprint/APA&2 GB&ProtoDUNE experience\\ \colhline
{\bf Supernova:}\\ \colhline
Single channel readout &270 MB& Uncompressed 90 s\\ \colhline
Four module readout& 600 TB& Uncompressed 100 s\\ \colhline
Trigger rate&1  per month&(assumption)\\
\end{dunetable}


\begin{dunefigure}[Expected physics-related activity
    rates in one FD module]{fig:daq-rates}{Expected physics-related activity
    rates in a single \nominalmodsize module. Figure~from \spchdaq{}. \label{sec:fd-daq:rates}
}
  \includegraphics[width=0.7\textwidth,clip,trim=6cm 6cm 10cm 2cm]{daq-event-type-rates-vs-energy.pdf}
\end{dunefigure}

\begin{dunetable}
[Expected DAQ yearly data rates]
{p{0.3\textwidth}p{0.1\textwidth}p{0.5\textwidth}}
{tab:daq-data-rates-sp}
{Summary of expected data rates for initial single-module running with \dword{sp} technology from Volume~\volnumbersp{}, \voltitlesp{}. \fixme{sp volume?} The rates assume no compression, and are given for a single \nominalmodsize module. Trigger primitives are not kept permanently; they are temporarily stored for one to two months at a time. The same applies to fake \dword{snb} data. Improved readout algorithms will be developed and evaluated with the initial data and are expected to provide about an order of magnitude reduction in data while retaining efficiency.}
Source& Annual Data Volume & Assumptions \\ \toprowrule
Beam interactions & 27 TB & 10 MeV threshold in coincidence with beam
time, including cosmic coincidence; \SI{5.4}{\milli\second} readout \\ \colhline
$^{39}$Ar, cosmics and atmospheric neutrinos & 10 PB & \SI{5.4}{\milli\second} readout \\ \colhline
Radiological backgrounds & $<2$ PB & $<1$ per month fake rate for SNB
trigger\\\colhline
Cold electronics calibration & 200 TB & \\ \colhline
Radioactive source calibration & 100 TB & $<10$ Hz source rate; single
APA readout; \SI{5.4}{\milli\second} readout \\\colhline
Laser calibration & 200 TB & 10$^6$ total laser pulses; half the
TPC channels illuminated per pulse; lossy
compression (zero-suppression) on all channels\\\colhline
Random triggers & 60 TB & 45 per day\\
\end{dunetable}



\subsection{Dual-phase Technology Data Estimates}

%For dual-phase, electrons drift the full height of the cryostat, emerge from the liquid and are collected - after gas amplification, on a grid of instrumented pads at the top of the detector.  The WA105 3x1x1 m test of this technology ran successfully in the summer of 2017\cite{Murphy:20170516}. 
Each \dword{dpmod} will have 153,600 readout channels. Drift time in the liquid argon is \SI{7.5}{ms}. Given 20,000 samples in an \SI{8}{ms} readout, the uncompressed event size is \SI{4.2}{GB} (for one drift window).  Due to gas amplification, the \dword{s/n} ratio is quite high, allowing lossless compression to be applied at the front-end  with a compression factor of ten, bringing the event size/module to \SI{.42}{GB}. Recording the entire module drift window can be considered a pessimistic figure, \fixme{??} since events are normally contained in smaller detector regions. A  \dword{fd} module can be treated as 20 smaller  detectors, each with a similar number  of readout channels as \dword{pddp} %the prototype currently being constructed 
at \dword{cern}, running in parallel, each one defining a region of interest  (\dword{roi}). For beam or cosmic events it is possible to record only the interesting \dword{roi}(s) with the compressed size of a single \dword{roi} being \SI{22}{MB}.

\subsection{Data Rates}
\subsubsection{Beam Coincident Rates}

Requiring  coincidence with the \dword{lbnf} beam will reduce the effective live-time from $\sim\,$\SI{1.2}{s}  to a \SI{5.4}{ms}  readout window (\SI{8}{ms} for \dword{dp}) coincident with the \SI{10}{\micro\second} beam spill, leading to an uncompressed data size for beam-coincident events of around \SI{24}{GB} for four \SI{17}{kt} \dwords{spmod} (and somewhat less for \dword{dp}), too high to record permanently at full rate.
Only a few thousand true beam interactions in the \dword{fd} modules are expected each year.  Compression and conservative triggering based on \dwords{pd} and ionization should reduce the data rate from beam interactions by several orders of magnitude without sacrificing efficiency.  Studies discussed in %the \dword{daq} section of this proposal 
\spchdaq{} for \dword{sp} \fixme{DP DAQ not included yet... }
indicate that high trigger efficiencies are achievable at an energy threshold of \SI{10}{MeV}, leading to event rates for beam-initiated  interactions of $\sim\,$6,400/year.
Table \ref{tab:daq-data-rates-sp}, adapted from \spchdaq{}, %the \dword{daq} section,
 summarizes the expected uncompressed rates from one \dword{spmod}. 

\subsubsection{Near Detector} 

The \dword{nd} configuration is not yet fully defined  but we do have substantial experience from \dword{t2k} and  \dword{microboone} at lower energies, and  \dword{minerva} at the  \dword{dune} beam energies on cosmic and beam interactions under similar conditions.  We can expect that a \dword{nd} will experience $\sim\,$1 beam interaction/m$^3$/beam pulse and non-negligible rates of cosmic rays. Initial estimates are that zero-suppressed data rates will be of order \SI{10}{MB/s} leading to yearly data volumes less than a PB.  

\subsubsection{Processes not in Synchronization with the Beam Spill} 

Processes not associated with the beam spill %These ah 
include \dword{snb} physics, atmospheric neutrinos, proton decay, neutron conversion, and solar neutrinos.  These processes are generally at lower energy, making triggering more difficult, and are  asynchronous, thus requiring an internal or external trigger.  In particular, \dword{snb} signals will consist of a large number of low-energy interactions spread throughout the \dword{fd} volume over a time period of 1-100 seconds. Buffering and storing 100 seconds of data would require around 20,000 readout windows, or around \SI{600}{TB} per four-module \dword{snb} readout.  At a rate of one fake \dword{snb} event/month, this is around \SI{7}{PB} of uncompressed data per year.  Reconstructing and analyzing these data will require substantial evolution in our software frameworks, which were developed to process small (\SIrange{1}{100}{MB}) events on single processors. This is a major thrust of \dword{dune}'s computing R\&D for the future. 

\subsubsection{
Calibration}

In addition to physics channels, continuous calibration of the detectors will be necessary.  It is likely that, for the \dword{fd} modules, calibration samples will  dominate the data volume. Cosmic-ray muons and atmospheric neutrino interactions will provide a substantial sample for energy and position calibration.  Dedicated runs with radioactive sources and laser calibration will also generate substantial and extremely valuable samples. Table \ref{tab:daq-data-rates-sp} includes estimates for the %single-phase far detector.   
\dword{spmod}. 
$^{39}$Ar decays at rates of $\sim\,$1/kg/sec provide a uniform illumination of the detector volume to monitor electron lifetimes. As discussed in the appendices to %the Physics volume
Volume~\volnumberphysics{}, \voltitlephysics{},  a single \SI{5}{ms} readout of the full detector would provide 50,000 decays for study.  A small number of such readouts per day would provide a global monitor of conditions at the 1\% level, but measurements sensitive on meter scales will require a factor of $10^4$ more data and can become a significant fraction of the calibration data stream. In summary, $^{39}$Ar cosmic ray and atmospheric neutrino signals collected for calibration make up the bulk of the uncompressed \dword{sp} data volume at $\sim\,$\SI{10}{PB/year} per \SI{17}{kt} module and will dominate the rates from the \dword{fd} modules.  


\subsubsection{Zero Suppression}

The data volumes discussed above are for un-zero-suppressed readout of the full \dword{fd}. A combination of local triggering, zero suppression, and  efficient lossless compression mechanisms can substantially reduce the final data volume. However previous experience in HEP indicates that signal processing must be done carefully and often happens well into data-taking when the data are well understood. 
\fixme{the "this but that" doesn't seem to follow. AH}
Experience from  \dword{microboone}, \dword{sbn} experiments, and the \dword{protodune} experiments will aid us in developing these algorithms, but it is likely that they will be applied later in the processing chain for \dword{sp}.  No zero-suppression is planned for \dword{dp}.

The constrained environment at \dword{surf} motivates a model where any further data reduction via zero suppression is done downstream, either on the surface or after delivery to computing facilities at \dword{fnal} or elsewhere. This could be analogous to the \dwords{hlt} used by \dword{lhc} experiments. \fixme{could be?} The %relative \fixme{relative?} 
optimization of data movement and processing location is an important consideration for the design of both the \dword{daq} and offline computing. %, but t AH
The remote location and resource limitations imposed by the underground detector motivate placement of large-scale computing resources offsite. 


\subsection{Simulation}
The bulk of data collected with the \dword{fd} is likely to be background, with real beam interaction events in the \dword{fd} numbering in the thousands per year, not millions. Thus, the size of simulation samples may be %less 
smaller than the unprocessed raw data considered above.  Lower-energy events are either very rare or can be simulated in sub-volumes of the whole detector.  As a result, while simulation will be important to the experiment, it should not dominate data volume as it does in many experiments.  

However, simulation inputs such as flux files, overlay samples, and shower libraries pose a special challenge because they must be distributed to simulation jobs carefully.   Proper simulation requires that these inputs be distributed in unbiased parcels.  This can be technically difficult to do efficiently in a widely distributed environment and will require thoughtful design. 

\subsection{Analysis}

Analysis formats have not yet been fully defined.  We anticipate that most analysis samples will be many times smaller than the raw data.  However, because they are idiosyncratic to particular analyses and even users,  producing and cataloguing them will require carefully designed tools and substantial oversight. 
We need a mix of official samples, produced by physics groups and distributed through a common catalog and file transfer mechanisms, as well as small user samples on local disks. 

Final oscillation parameter scans with a large number of %nuisance 
parameters can be quite CPU-intensive.  For example, the \dword{nova} collaboration's recent physics results required tens of millions of  HPC CPU hours at the NERSC facility at \dword{lbnl}. DUNE collaborators used simpler models but the same techniques to generate some of the results presented in Volume~\volnumberphysics{}, \voltitlephysics{}. These large-scale analysis projects will require collaboration-wide coordination of resources and will benefit greatly from optimization for specific architectures.

\subsection{Data Storage and Retention Policies}
Some of the samples listed above are extremely valuable and will require conservative retention policies.   Examples include real neutrino and cosmic ray interactions in the far detector, most of the near detector data, and any real \dword{snb} events.  These data streams may require multiple copies be retained. Calibration samples and, potentially, fake \dword{snb} triggers may be stored temporarily and discarded after processing. 



\subsection{Summary}
In summary, uncompressed data volumes will be dominated by calibration for the \dword{fd} modules (10-15~PB/year/module) and by beam and cosmic ray interactions in the near detector.  With four \dword{fd} modules and a conservative factor of four for lossless compression, a total compressed data volume of 10-15~PB/year for the \dword{fd} is anticipated. Near detector rates are not yet established, but are likely to be smaller.   
%After discussion with the \dword{sp} Trigger/\dword{daq} group, we have 
The \dword{csc} has requested that the \dword{sp} \dword{daq} %they 
include %as upper limits ah 
in their design a  maximum data transfer rate from the \dword{fd} to \dword{fnal} of \surffnalbw, which is consistent with projected network bandwidths in the mid 2020's, and a limit of \SI{30}{PB/year} raw data stored to tape.  
%Table \ref{daq:datarates} summarizes the data rates expected from the \dword{daq} section of this proposal. 


\section{ProtoDUNE-SP as an Example}
\label{ch:exec-comp-proto-SP}
The first \dword{protodune} \dword{sp} run at \dword{cern} in late 2018 has already led to a %small-scale 
substantial test of the global computing model.  In the following, we will describe the \dword{protodune} data design and the lessons learned from our experience. Much of this carries over into planning for full \dword{fd} operations. 

\subsection{Introduction}

\dword{pdsp} ran at \dword{cern} in the NP04 beamline from September to November of 2018. Since then, studies of cosmic rays have continued. Before that run, several data challenges at high rate validated the data transfer mechanisms. 

\subsection{Data Challenges}

\dword{protodune} performed a series of data challenges, starting in late 2017.  Simulated data were passed through the full chain from the event builder machines to tape storage at \dword{cern} and \dword{fermilab} at rates up to \SI{2}{GB/s}.  These studies allowed optimizing the network and storage elements well before the start of data taking.
Note that the full \dword{dune} \dword{fd} would, in writing \SI{30}{PB/s}, produce data at rates similar to  those demonstrated in the 2018 data challenges. While data rates are likely not technically challenging, the integrated data volume from an experiment that is up 99\% of the time over several decades will be. 

\subsection{Commissioning and Physics Operations}

The first phase of operations was commissioning the detector readout systems while the \dword{lar} reached full purity.  Data were taken with cosmic rays and beam during the commissioning period. Once high \dword{lar} purity had been achieved, physics data were  taken with beam through October and half of November. %Normal trigger rates were approximately 25 Hz, but tests were done at rates up to 100 Hz. 
Since the beam run ended, cosmic ray data continues to be taken with varying detector conditions, such as modified high voltage and purity, and new readout schemes. 



\subsection{Data Volumes}
\dword{pdsp} comprises a \dword{tpc} with  six \dword{apa}s, \dword{pd}s, and a \dword{crt}. In addition, the NP04 beamline is instrumented with hodoscopes and Cerenkov counters to generate beam triggers. Random triggers  were generated at lower rates to collect unbiased cosmic ray information. The data volume from the test beam run was dominated by readout of the \dword{tpc}. % Each \dword{apa} has 2,560 channels and reads out 12 bit \dword{adc} values at 2 MHz. 
The nominal readout window during beam running was  \SI{3}{ms} to match the drift time at the full voltage of \SI{180}{kV}, which was maintained for most of the run.  The size of the \dword{tpc} data without compression was  \SI{138}{MB/event}, not including headers.  The uncompressed event size including all \dword{tpc} information and \dword{crt} and \dword{pd} data was \SIrange{170}{180}{MB}. Compression was implemented just before the October beam physics run, reducing the total size per event from around \SI{180}{MB} to \SI{75}{MB}.  In total, 8.1 million beam events were written with a total size of \SI{5205}{TB}.  An additional PB of commissioning data and cosmic ray data has also been recorded. 

\begin{comment}\ignore{Table \ref{
tab:exec-comp-pd-volumes} summarizes the raw data volumes.

\begin{dunetable}[Data volumes]{lrr}{tab:exec-comp-pd-volumes}{Data volumes  recorded by \dword{pdsp} as of December 2018.}
Type  & Events & Size\\ \rowtitlestyle
Raw Beam&8.08 M& 520 TB \\ \colhline
Raw Cosmics&3.46 M& 271 TB\\ \colhline
Commissioning&3.86 M& 388 TB\\ \colhline
Pre-commissioning&13.89 M&641 TB\\
\end{dunetable}
}\end{comment}

Events were written out in \SI{8}{GB} raw data files with each containing approximately 100 events. The beam was live for two 4.5 s spills every 32 s beam cycle, and data were taken at  rates up to 50 Hz (typically 25 Hz), leading to compressed \dword{dc} rates of \SIrange{400}{800}{MB/s} from the detector.  

\begin{comment}\ignore{
\subsection{ProtoDUNE-SP Data Streams}
The \dword{pdsp} data consist of multiple sources in addition to the \dword{tpc} data. One of the major challenges for offline computing systems is merging these data streams into a coherent whole for analysis.  Table \ref{tab:exec-comp-pd-sources} lists the data sources used and their granularity. 

\begin{dunetable}[Data sources]{lrr}{tab:exec-comp-pd-sources}{Data sources.  }
Type & indexed by & destination\\ \colhline
TPC  & run/event & event data\\ \colhline
Photon Detector data & run/event & event data\\ \colhline
Cosmic Ray Tagger & run/event & event data\\ \colhline
Beamline devices & timestamp & beam database\\ \colhline
Detector conditions & timestamp & slow controls database\\ \colhline
DAQ configuration & run & files/elisa logbook\\ \colhline
Run quality & run & human generated spreadsheets\\ \colhline
Data quality & run/event/time & Data Quality web application\\ \colhline
File metadata & file & sequential access via metadata file database\\
\end{dunetable}
}
\end{comment}

\subsection{Reconstruction of ProtoDUNE-SP Data}
Thanks to substantial previous effort by the \dword{35t}, \dword{microboone}, and the \dword{lar} \dword{tpc} community, high quality algorithms were already in place to reconstruct the \dword{tpc}  data.  As a result, a first pass reconstruction of the \dword{pdsp} data with beam triggers was completed by early December, less than a month after data taking ended.  Results from that reconstruction are presented in \physchtools %the Methods section of Volume~\volnumberphysics, \voltitlephysics{} 
with some highlights summarized here. 



\subsection{Data Preparation}

Before pattern recognition, data from the \dword{protodune} detector is
unpacked and copied to a standard format within the \dword{art} framework based on \dword{root} objects. 
This reformatted raw data includes the waveform for each channel, consisting of 6,000-15,000,  12-bit, 0.5 $\mu$sec samples. 
The first step in reconstruction is data preparation to
convert each \dword{adc} waveform into a calibrated charge waveform with
signals proportional to charge. At the end of data preparation, hit \dword{roi}s are identified, and the data outside these regions are discarded.  This leads to significant reduction in data size. This process is described more fully in~\cite{bib:docdb12349}. % and in the Methods section of the Volume~\volnumberphysics, \voltitlephysics{}.% but is summarized here: \fixme{get methods sec ref}
\begin{comment}\ignore{
\begin{enumerate}
\item Each waveform is unpacked into integers.
\item Pedestals are determined per event/per channel from the most common \dword{adc} value. 
\item Pedestals and calibrations are applied. %\label{local:ped}
\item Bad channels, sticky bits, and other known hardware problems are corrected or removed.
\item Signal undershoot that creates a long negative tail is removed. 
\item The waveforms  are deconvoluted.  In the first processing, this was done with simple 1D  convolution for a single wire.  A \twod  method of deconvoluting a detailed detector electrostatic field map, originally developed for \dword{microboone}\cite{Adams:2018dra}, is  now available for \dword{protodune} and will be used in the future reconstruction passes.  It properly undoes the long-range induction effects while keeping efficiency high and bias low.  The deconvolution Fourier transforms the waveform, replaces the  bipolar field response function with a unipolar function, applies a low-pass filter to remove high-frequency noise, and then transforms back.

\fixme{One dimensional (1d) and two dimensional (\twod) should be consistent with one another and probably in LATEX code. (Anne says: I just use \twod and \threed from defs for consistency.)}




\item Finally, regions of interest are defined where the signal exceeds a given threshold, and time slices well outside the \dshort{roi} are dropped. These data feed into the reconstruction algorithms for further pattern recognition. %\label{local:roi}
\end{enumerate}
}
\end{comment}

Figures~\ref{fig:ch-exec-comp-chtraw} and~\ref{fig:ch-exec-comp-chtroi} illustrate the transformation of \dword{tpc} data  during data preparation. Note that this represents one wire plane for 3 ms.  A full 5.4 ms readout of four \nominalmodsize modules would contain a factor of 3,000 more information than this image.

\begin{figure}[t]
\includegraphics[width=\textwidth,angle=0]{comp-evd_twq-proj_5449_20926_raw.png}
\caption[Example of pedestal-subtracted data for one of the ProtoDUNE-SP  wire planes]{Example of pedestal-subtracted data for one of the ProtoDUNE-SP  wire planes.  The top pane shows the ADC values in a V (induction) plane with the x-axis being channel number and the y-axis, time slice. The bottom pane shows the bipolar pulses induced on one channel. 
}
\label{fig:ch-exec-comp-chtraw}
\end{figure}


\begin{figure}[t]
 \includegraphics[width=\textwidth]{comp-evd_twq-proj_5449_20926_decon.png}
\caption[Pedestal-subtracted data for one of the ProtoDUNE-SP  wire planes, additional processing]{
Pedestal-subtracted data for one of the ProtoDUNE-SP  wire planes, as Figure~\ref{fig:ch-exec-comp-chtraw}, but shown after calibration, cleanup, deconvolution and \dword{roi} finding. 
}
\label{fig:ch-exec-comp-chtroi}
\end{figure}


\subsection{Computational Characteristics of Data Preparation and Deconvolution }

Decoding for \dword{pdsp} was originally done with all six \dword{apa}s in memory. Each \SI{3}{ms} of \dword{apa} readout consists of more than \SI{15}{M} 16-bit values. Decompressing and converting this information to floating point format causes substantial memory expansion. 
  Data with a 7.5 ms window were also taken. 
The input and output event sizes and reconstruction time scale were found to scale linearly with the readout window and with the number of \dword{apa}s processed. 


Because electrical signals are correlated between channels within an \dword{apa} wire plane but not between planes, processing each wire plane (three per \dword{apa}) independently reduces the memory footprint.
However,  while subdividing the detector into wire planes reduces the memory footprint for short (beam-related) readouts, it is  not a viable solution for the long readouts expected for \dword{snb} events. We are still exploring the best strategy for dealing with these much larger ($\times 10,000$) time windows. 
The \dword{daq} consortium is exploring methods for segmenting large events (such as \dwords{snb}) into  smaller of \dword{roi}s in both time and space for efficient readout.  As long as those regions are on the scale of single interactions, the resulting data should fit in a reasonable memory budget at the expense of tracking and collating many distributed interactions. 

The operations performed in signal processing require few decisions, but do include operations such as fast Fourier transforms and deconvolution.  These operations are well suited for GPU and parallel processing. We are actively exploring multi-threaded processing for all data preparation algorithms. 


\subsection{Reconstruction Characteristics}



Once \dword{roi}s have been identified, several \threed  reconstruction packages are used. For the first reconstruction pass in November, the  \dword{pandora}~\cite{Acciarri:2017hat}, \dword{wirecell}~\cite{wirecell}, and \dword{pma}~\cite{ref:PMA}  frameworks were used with results described in Volume~\volnumberphysics{}, \voltitlephysics{}. 
Figure~\ref{fig:ch-exec-comp-tracking}  is taken from the from Volume~\volnumberphysics{} and illustrates the measured efficiency for the Pandora algorithm reconstructing a triggered beam particle as a function of momentum for the simulation and data for selected data taking runs. As can be seen, the efficiency is already quite high and reasonably well simulated.




Full reconstruction of these \dword{pdsp} interactions, with beam particles and approximately 60 cosmic rays per readout window, took of order 600 sec/event with around 200 sec in the signal processing and hit finding stages, and the remaining time divided between three different pattern recognition algorithms. Output event records were substantially smaller (22 MB compressed) and still dominated by the information for \dword{tpc} hits above threshold. 

All of these algorithms are currently being run on conventional UNIX CPUs using \dword{osg}/\dword{wlcg} grid computing  infrastructure. Deep learning techniques based on image pattern recognition algorithms are also being developed. Many of these algorithms can be adapted to run on \dwords{hpc} assets, although the optimal architecture for \threed reconstruction likely differs from the optimum for hit finding.


\begin{figure}[htp]
\centering
\includegraphics[height=4in]{graphics/BeamParticleEfficiencyVsMomentum.pdf}
\caption[Efficiency of reconstruction for the triggered test beam particle]{The efficiency of reconstruction for the triggered test beam particle as a function of particle
momentum in data (red) and simulation (black). Figure~5.27 from Volume~\volnumberphysics{}, \voltitlephysics{}.}
\label{fig:ch-exec-comp-tracking}
\end{figure}






\begin{comment}\ignore{
\begin{dunetable}
[Data storage  and CPU needs for reconstruction of ProtoDUNE test beam data]
{llrrrr}{tab:exec-comp-needs}{Data storage and CPU needs for reconstruction of ProtoDUNE-SP test beam data taken in 2018 and projections for 2019-2021.  We assume two copies of raw data are stored and that each event is reconstructed twice.  Analysis and simulation are estimated to be of order the same CPU use as reconstruction based on the 2018 experience.}%\rowtitlestyle
Detector& value &
2018&
2019&
2020&
2021\\\colhline
&&As built\\\colhline
SP&
Events, M&
15.1&
13.0&
6.5&
40.5\\\colhline
&
Raw data, TB&
1047&
2239&
1120&
2799\\\colhline
&
Reco data, TB&
2094&
4479&
2239&
5599\\\colhline
&
CPU, MH&
5.0&
4.3&
2.2&
13.5\\\colhline
DP&
Events, M&
0.0&
101.1&
56.2&
119.9\\\colhline
&
Raw data, TB&
0&
809&
449&
1799\\\colhline
&
Reco data, TB&
0&
1617&
899&
3598\\\colhline
&
CPU, MH&
0.0&
33.7&
18.7&
40.0\\\colhline
total&
Events, M&
15.1&
114.0&
62.6&
160.4\\\colhline
&2x
Raw data, TB&
2094&
6096&
3138&
9197\\\colhline
&
Reco data, TB&
2094&
6096&
3138&
9197\\\colhline
total&Storage, TB&
4188&
12193&
6276&
18394\\\colhline
&
Reco CPU, MH&
5.0&
38.0&
20.9&
53.5\\\colhline
&
Analysis CPU, MH&
5.0&
40.0&
40.0&
40.0\\\colhline
Total&CPU, MH&
10.0&
78.0&
60.9&
93.5\\
\end{dunetable}
}\end{comment}



\subsection{Lessons Learned}
The first \dword{pdsp} run has given us very valuable information for planning the full \dword{dune} computing model. 

\begin{itemize}
    \item Data and simulation challenges led to a reasonably mature and robust model for acquiring, storing, and cataloging the main data stream at design rates.
    \item The experiment integrated several existing grid sites and used substantial opportunistic resources.  This allowed initial processing of data within one month of the end of the run.
    \item Prototype infrastructure was in place for provisioning, authentication and authorization, data management, networking, file catalog, and workflow management. 
    \item Reconstruction algorithms were available and allowed immediate studies of detector performance and calibration. 
    \item Beam information was successfully integrated into processing through the \dword{ifbeam} database.
    \item Auxiliary information from, for example, slow controls, was not fully integrated into processing which led to  manual input of running conditions by shift personnel and offline incorporation of that information into the data catalog. This has led to closer collaboration with the \dword{daq} and \dword{cisc} groups in designing robust interfaces for configurations and conditions. 
\end{itemize}

Overall, the \dword{pdsp} data taking and processing was a success, despite being overly dependent on doing things manually because automated processes were not always in place. Considerable effort must go into integrating detector conditions, data migration, workflow systems, and \dword{hpc}s with multi-threaded and vectorized software.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{comment}\ignore{
\section{Data Model for the Far and Near Detectors}
\label{ch:exec-comp-mod}

%%%%%%%%%%%%%%%%%%%%
%\subsection{Introduction}
%\label{ch:exec-comp-mod-int}
In parallel with the \dword{pdsp} data, a joint data model task force was formed by the \dword{daq} and \dword{csc} to build a framework for the full \dword{dune} \dword{nd} and \dword{fd}. 
The data model task force grappled with the problems of efficiently triggering, reading out, and storing data on multiple time scales from an enormous detector.

They defined major concepts.
\todo{Request from LBNC to shorten this }

\begin{itemize}

\item{Configuration:} Set of parameters that define the persistent, expected detector state. Globally, this corresponds to a desirable state for the detector, capable of providing data of physics or calibration quality. Each component of the detector may have its own configuration.
 
\item{Run:} Period over which data has been collected across some set of desired components in a consistent configuration.
 
\item{Sub-run:} Period within a run over which data has been collected across some set of desired components in a consistent configuration. The set of desired components in a sub-run must be a subset of the desired components for a run and is the set of components over which data is expected.
 
(Time-based rollovers of runs and sub-runs may be automatic. Differences between sub-run and run due to configuration or changes in the desired components will be tracked by the \dword{daq} and may be either manual or automatic.)
 
\item{Trigger:} Data from the desired components in a sub-run over a readout window. This would typically be centered around a trigger time and is what is recorded by the \dword{daq}. The readout window may be subdivided into frames as determined by the \dword{daq}.
 
\item{Event:} Subset of a trigger isolated in time and space containing an independent interaction in the detector. Events may overlap in space or time within the same trigger. This is generally determined by the offline reconstruction of data in a frame.

\end{itemize}

These definitions are intended to allow triggering, recording, and reconstruction of interactions in subsets of the detector. While the whole detector (or time window) can produce enormous amounts of data, any individual interaction should span a reasonably short time and spatial volume. A data model that can isolate individual interactions  allows interactions to be efficiently stored and reconstructed. 


The main data stream will be augmented by beam, slow controls, \dword{daq} configuration, and calibration information. 

This work continues and informs  the  joint  calibration, \dword{csc} and \dword{daq} designs.

}\end{comment}


\section{Conclusion}

The \dword{dune} \dword{csc} has already undergone a substantial test with the successful run of \dword{pdsp}, including demonstrating data movement to storage at \SI{2}{GB/s}, reconstructing the full test beam sample with high-quality algorithms, and beginning analysis of the multiple PB reconstructed data. 

The \dword{csc} is now working with the global HEP computing community to evaluate and specify modern infrastructure that will serve the needs of \dword{dune} and the rest of the community.  We plan to collaborate wherever possible with other experiments where we have common technical challenges. However, the extremely large but simple events generated by \dword{lar} \dwords{tpc}, even with short readouts, present a unique challenge. 

Over the next two years our major activities  will be  thoroughly reviewing available and potential tools, continuing collaborations, and acquiring the resources necessary to launch this large suite of ambitious projects. 


